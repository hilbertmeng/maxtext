{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "177b3e1e-aa93-4737-9b6a-4bbc766965cd",
   "metadata": {},
   "source": [
    "# 加载基础dense模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90bd2fa6-f76b-413a-bc29-2e5ae09951c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow==2.16.1\n",
    "# pip install numpy==1.26.4\n",
    "\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import asyncio\n",
    "import argparse\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "os.environ[\"JAX_PLATFORMS\"] = \"cpu\"\n",
    "from etils import epath\n",
    "import json\n",
    "import base64\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import orbax\n",
    "import orbax.checkpoint as ocp\n",
    "from etils import epath\n",
    "from jax.sharding import PartitionSpec as PS\n",
    "from flax.traverse_util import flatten_dict, unflatten_dict\n",
    "\n",
    "\n",
    "METADATA_FILE = '_METADATA'\n",
    "_CHECKPOINT_FILE = 'checkpoint'\n",
    "\n",
    "read_dir = 'gs://llm_base_models_us-east5/v5p_256/7B/xm_45x7B_moe/checkpoints/0/state'\n",
    "# save_dir = 'gs://llm_base_models_us-east5/v5p_256/7B/xm_45x7B_moe_0919_test/checkpoints/'\n",
    "\n",
    "# read_dir = 'gs://jax_llm_data_us-east5/test/pile_moe_0919/checkpoints/600/state'\n",
    "# save_dir = 'gs://llm_base_models_us-east5/v5p_256/7B/xm_45x7B_moe_0920_1.2k/checkpoints/'\n",
    "\n",
    "read_dir = 'gs://llm_base_models_us-east5/v5p_256/7B/PileDCSlimLlama7B32Kx4x256x1v5p_0713/ocdbt/checkpoints/448800/state'\n",
    "save_dir = 'gs://llm_base_models_us-east5/v5p_256/7B/xm_45x7B_moe_0922/checkpoints/'\n",
    "\n",
    "read_dir = epath.Path(read_dir) \n",
    "save_dir = epath.Path(save_dir)\n",
    "\n",
    "metadata_path = read_dir / METADATA_FILE\n",
    "back_metadata_path = read_dir / f'{METADATA_FILE}.back'\n",
    "try:\n",
    "    metadata_path.rename(back_metadata_path)\n",
    "except:\n",
    "    pass\n",
    "metadata_path.unlink(missing_ok=True) # delete\n",
    "structure_path = read_dir / _CHECKPOINT_FILE\n",
    "msgpack = ocp.aggregate_handlers.MsgpackHandler(0)\n",
    "structure = msgpack.deserialize(structure_path)\n",
    "# backup original checkpoint fil\n",
    "back_structure_path = read_dir / 'checkpoint_back'\n",
    "back_structure = structure.copy()\n",
    "if not back_structure_path.exists():\n",
    "    asyncio.run(msgpack.serialize(back_structure_path, item=back_structure))\n",
    "print(f'Old structure file keys: {structure.keys()}')\n",
    "remove_keys = ['opt_state', 'step'] # select the weight name you don't want to load, all weight name: opt_state, step, params\n",
    "_ = [structure.pop(key) for key in remove_keys if key in structure]\n",
    "print(f'New structure file keys: {structure.keys()}')\n",
    "asyncio.run(msgpack.serialize(structure_path, item=structure))  # rewrite struct file\n",
    "\n",
    "# load model based struct, note: axes must same as training\n",
    "mesh_axes = ['data', 'stage', 'fsdp', 'fsdp_transpose', 'sequence', 'tensor', 'autoregressive']\n",
    "devices = np.asarray(jax.devices()).reshape([1] * len(mesh_axes))\n",
    "mesh = jax.sharding.Mesh(devices, mesh_axes)\n",
    "sharding = jax.sharding.NamedSharding(mesh, PS()) # Sharding is None because we use cpu to load weights\n",
    "weight_dtype = jnp.bfloat16 # set restore weights dtype\n",
    "restore_args = {}\n",
    "for k, v in flatten_dict(structure).items():\n",
    "    restore_args[k] =  ocp.ArrayRestoreArgs(restore_type=jax.Array, dtype=weight_dtype, sharding=sharding)\n",
    "restore_args = unflatten_dict(restore_args)\n",
    "ckptr = ocp.Checkpointer(ocp.PyTreeCheckpointHandler())\n",
    "w = ckptr.restore(read_dir, args=ocp.args.PyTreeRestore(restore_args=restore_args))\n",
    "structure_path = read_dir / _CHECKPOINT_FILE\n",
    "# rewrite struct file, otherwise occur error when continue training\n",
    "asyncio.run(msgpack.serialize(structure_path, item=back_structure))\n",
    "while 'params' in w:\n",
    "    w = w['params']\n",
    "xm3p5_w = {'.'.join(k): np.array(v) for k, v in flatten_dict(w).items()}\n",
    "\n",
    "try:\n",
    "    back_metadata_path.rename(metadata_path)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05df67c1-42fb-4fb6-aead-663acb3a307b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in xm3p5_w.items():\n",
    "    print(k, v.shape, v.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "369d123f-5ea9-4c96-a932-c108114ce3c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: decoder.decoder_norm.scale take: 0.000s\n",
      "k: decoder.layers.mlp_0.mgate.kernel take: 0.001s\n",
      "0\n",
      "k: decoder.layers.mlp_0.wi_0.kernel take: 0.001s\n",
      "0\n",
      "copy_w: (44, 12, 4096, 5632) copy_w: float16 v: (1, 12, 4096, 5632) unshared_mlp: decoder.layers.unshared_mlp_0.wi_0.kernel\n",
      "k: decoder.layers.mlp_0.wi_1.kernel take: 122.405s\n",
      "0\n",
      "copy_w: (44, 12, 4096, 5632) copy_w: float16 v: (1, 12, 4096, 5632) unshared_mlp: decoder.layers.unshared_mlp_0.wi_1.kernel\n",
      "k: decoder.layers.mlp_0.wo.kernel take: 244.480s\n",
      "0\n",
      "copy_w: (44, 12, 5632, 4096) copy_w: float16 v: (1, 12, 5632, 4096) unshared_mlp: decoder.layers.unshared_mlp_0.wo.kernel\n",
      "k: decoder.layers.mlp_1.mgate.kernel take: 368.050s\n",
      "1\n",
      "k: decoder.layers.mlp_1.wi_0.kernel take: 368.050s\n",
      "1\n",
      "k: decoder.layers.mlp_1.wi_1.kernel take: 368.050s\n",
      "1\n",
      "k: decoder.layers.mlp_1.wo.kernel take: 368.050s\n",
      "1\n",
      "k: decoder.layers.mlp_2.mgate.kernel take: 368.050s\n",
      "2\n",
      "k: decoder.layers.mlp_2.wi_0.kernel take: 368.050s\n",
      "2\n",
      "k: decoder.layers.mlp_2.wi_1.kernel take: 368.050s\n",
      "2\n",
      "k: decoder.layers.mlp_2.wo.kernel take: 368.050s\n",
      "2\n",
      "k: decoder.layers.mlp_3.mgate.kernel take: 368.050s\n",
      "3\n",
      "k: decoder.layers.mlp_3.wi_0.kernel take: 368.050s\n",
      "3\n",
      "k: decoder.layers.mlp_3.wi_1.kernel take: 368.050s\n",
      "3\n",
      "k: decoder.layers.mlp_3.wo.kernel take: 368.050s\n",
      "3\n",
      "k: decoder.layers.post_self_attention_layer_norm_0.scale take: 368.050s\n",
      "k: decoder.layers.post_self_attention_layer_norm_1.scale take: 368.050s\n",
      "k: decoder.layers.post_self_attention_layer_norm_2.scale take: 368.050s\n",
      "k: decoder.layers.post_self_attention_layer_norm_3.scale take: 368.050s\n",
      "k: decoder.layers.pre_self_attention_layer_norm_0.scale take: 368.050s\n",
      "k: decoder.layers.pre_self_attention_layer_norm_1.scale take: 368.050s\n",
      "k: decoder.layers.pre_self_attention_layer_norm_2.scale take: 368.050s\n",
      "k: decoder.layers.pre_self_attention_layer_norm_3.scale take: 368.050s\n",
      "k: decoder.layers.self_attention_0.AttentionOp_0.dyn_w_proj.dd.kernel take: 368.050s\n",
      "k: decoder.layers.self_attention_0.AttentionOp_0.dyn_w_proj.dw1.kernel take: 368.050s\n",
      "k: decoder.layers.self_attention_0.AttentionOp_0.dyn_w_proj.qkw take: 368.050s\n",
      "k: decoder.layers.self_attention_0.k_norm.scale take: 368.050s\n",
      "k: decoder.layers.self_attention_0.key.kernel take: 368.050s\n",
      "k: decoder.layers.self_attention_0.out.kernel take: 368.050s\n",
      "k: decoder.layers.self_attention_0.q_norm.scale take: 368.050s\n",
      "k: decoder.layers.self_attention_0.query.kernel take: 368.050s\n",
      "k: decoder.layers.self_attention_0.value.kernel take: 368.050s\n",
      "k: decoder.layers.self_attention_1.AttentionOp_0.dyn_w_proj.dd.kernel take: 368.050s\n",
      "k: decoder.layers.self_attention_1.AttentionOp_0.dyn_w_proj.dw1.kernel take: 368.050s\n",
      "k: decoder.layers.self_attention_1.AttentionOp_0.dyn_w_proj.qkw take: 368.050s\n",
      "k: decoder.layers.self_attention_1.k_norm.scale take: 368.050s\n",
      "k: decoder.layers.self_attention_1.key.kernel take: 368.050s\n",
      "k: decoder.layers.self_attention_1.out.kernel take: 368.050s\n",
      "k: decoder.layers.self_attention_1.q_norm.scale take: 368.050s\n",
      "k: decoder.layers.self_attention_1.query.kernel take: 368.050s\n",
      "k: decoder.layers.self_attention_1.value.kernel take: 368.050s\n",
      "k: decoder.layers.self_attention_2.AttentionOp_0.dyn_w_proj.dd.kernel take: 368.050s\n",
      "k: decoder.layers.self_attention_2.AttentionOp_0.dyn_w_proj.dw1.kernel take: 368.050s\n",
      "k: decoder.layers.self_attention_2.AttentionOp_0.dyn_w_proj.qkw take: 368.050s\n",
      "k: decoder.layers.self_attention_2.k_norm.scale take: 368.050s\n",
      "k: decoder.layers.self_attention_2.key.kernel take: 368.050s\n",
      "k: decoder.layers.self_attention_2.out.kernel take: 368.050s\n",
      "k: decoder.layers.self_attention_2.q_norm.scale take: 368.050s\n",
      "k: decoder.layers.self_attention_2.query.kernel take: 368.050s\n",
      "k: decoder.layers.self_attention_2.value.kernel take: 368.050s\n",
      "k: decoder.layers.self_attention_3.AttentionOp_0.dyn_w_proj.dd.kernel take: 368.050s\n",
      "k: decoder.layers.self_attention_3.AttentionOp_0.dyn_w_proj.dw1.kernel take: 368.050s\n",
      "k: decoder.layers.self_attention_3.AttentionOp_0.dyn_w_proj.qkw take: 368.050s\n",
      "k: decoder.layers.self_attention_3.k_norm.scale take: 368.050s\n",
      "k: decoder.layers.self_attention_3.key.kernel take: 368.050s\n",
      "k: decoder.layers.self_attention_3.out.kernel take: 368.050s\n",
      "k: decoder.layers.self_attention_3.q_norm.scale take: 368.050s\n",
      "k: decoder.layers.self_attention_3.query.kernel take: 368.051s\n",
      "k: decoder.layers.self_attention_3.value.kernel take: 368.051s\n",
      "k: decoder.logits_dense.kernel take: 368.051s\n",
      "k: token_embedder.embedding take: 368.051s\n"
     ]
    }
   ],
   "source": [
    "## 基于dense模型保存和moe相同名字的参数\n",
    "def convert_to_jnp(params, remove_keys=[]):\n",
    "    convert_params = {}\n",
    "    for k, v in params.items():\n",
    "        r = 0\n",
    "        for remove_key in remove_keys:\n",
    "            if remove_key in k: \n",
    "                r = 1\n",
    "                break\n",
    "        if r: continue\n",
    "        k = tuple(k.split('.'))\n",
    "        convert_params[k] = v\n",
    "        # convert_params[k] = jnp.array(v).astype(jnp.bfloat16)\n",
    "    for k, v in convert_params.items():\n",
    "        print(k, v.shape, v.dtype)\n",
    "    return convert_params\n",
    "\n",
    "\n",
    "def save_params(step, save_dir, params):\n",
    "    item = {\n",
    "            'state': orbax.checkpoint.AsyncCheckpointer(orbax.checkpoint.PyTreeCheckpointHandler(use_ocdbt=False)),\n",
    "                    }\n",
    "    # new_params = {tuple(k.split('.')): v for k,v in params.items()}\n",
    "    unflatten_params = unflatten_dict(params)\n",
    "    for k, v in params.items():\n",
    "        print(k, v.shape, v.dtype)\n",
    "    mngr = orbax.checkpoint.CheckpointManager(save_dir, item)\n",
    "    if 'params' not in unflatten_params: unflatten_params = {'params': unflatten_params}\n",
    "    mngr.save(step, items={'state': {'params': unflatten_params}})\n",
    "\n",
    "convert_params = convert_to_jnp(xm3p5_w, remove_keys=['mgate'])\n",
    "save_params(0, save_dir, convert_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8e2e142-8fec-4e02-9cc8-933316f039d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: decoder.decoder_norm.scale take: 0.000s\n",
      "k: decoder.layers.mlp_0.mgate.kernel take: 0.000s\n",
      "0\n",
      "k: decoder.layers.mlp_0.wi_0.kernel take: 0.000s\n",
      "0\n",
      "k: decoder.layers.mlp_0.wi_1.kernel take: 0.000s\n",
      "0\n",
      "k: decoder.layers.mlp_0.wo.kernel take: 0.000s\n",
      "0\n",
      "k: decoder.layers.mlp_1.mgate.kernel take: 0.000s\n",
      "1\n",
      "k: decoder.layers.mlp_1.wi_0.kernel take: 0.000s\n",
      "1\n",
      "k: decoder.layers.mlp_1.wi_1.kernel take: 0.000s\n",
      "1\n",
      "k: decoder.layers.mlp_1.wo.kernel take: 0.000s\n",
      "1\n",
      "k: decoder.layers.mlp_2.mgate.kernel take: 0.000s\n",
      "2\n",
      "k: decoder.layers.mlp_2.wi_0.kernel take: 0.000s\n",
      "2\n",
      "k: decoder.layers.mlp_2.wi_1.kernel take: 0.000s\n",
      "2\n",
      "k: decoder.layers.mlp_2.wo.kernel take: 0.000s\n",
      "2\n",
      "k: decoder.layers.mlp_3.mgate.kernel take: 0.000s\n",
      "3\n",
      "k: decoder.layers.mlp_3.wi_0.kernel take: 0.000s\n",
      "3\n",
      "k: decoder.layers.mlp_3.wi_1.kernel take: 0.000s\n",
      "3\n",
      "k: decoder.layers.mlp_3.wo.kernel take: 0.000s\n",
      "3\n",
      "k: decoder.layers.post_self_attention_layer_norm_0.scale take: 0.000s\n",
      "k: decoder.layers.post_self_attention_layer_norm_1.scale take: 0.000s\n",
      "k: decoder.layers.post_self_attention_layer_norm_2.scale take: 0.000s\n",
      "k: decoder.layers.post_self_attention_layer_norm_3.scale take: 0.000s\n",
      "k: decoder.layers.pre_self_attention_layer_norm_0.scale take: 0.000s\n",
      "k: decoder.layers.pre_self_attention_layer_norm_1.scale take: 0.000s\n",
      "k: decoder.layers.pre_self_attention_layer_norm_2.scale take: 0.000s\n",
      "k: decoder.layers.pre_self_attention_layer_norm_3.scale take: 0.000s\n",
      "k: decoder.layers.self_attention_0.AttentionOp_0.dyn_w_proj.dd.kernel take: 0.000s\n",
      "k: decoder.layers.self_attention_0.AttentionOp_0.dyn_w_proj.dw1.kernel take: 0.000s\n",
      "k: decoder.layers.self_attention_0.AttentionOp_0.dyn_w_proj.qkw take: 0.000s\n",
      "k: decoder.layers.self_attention_0.k_norm.scale take: 0.000s\n",
      "k: decoder.layers.self_attention_0.key.kernel take: 0.000s\n",
      "k: decoder.layers.self_attention_0.out.kernel take: 0.000s\n",
      "k: decoder.layers.self_attention_0.q_norm.scale take: 0.000s\n",
      "k: decoder.layers.self_attention_0.query.kernel take: 0.000s\n",
      "k: decoder.layers.self_attention_0.value.kernel take: 0.001s\n",
      "k: decoder.layers.self_attention_1.AttentionOp_0.dyn_w_proj.dd.kernel take: 0.001s\n",
      "k: decoder.layers.self_attention_1.AttentionOp_0.dyn_w_proj.dw1.kernel take: 0.001s\n",
      "k: decoder.layers.self_attention_1.AttentionOp_0.dyn_w_proj.qkw take: 0.001s\n",
      "k: decoder.layers.self_attention_1.k_norm.scale take: 0.001s\n",
      "k: decoder.layers.self_attention_1.key.kernel take: 0.001s\n",
      "k: decoder.layers.self_attention_1.out.kernel take: 0.001s\n",
      "k: decoder.layers.self_attention_1.q_norm.scale take: 0.001s\n",
      "k: decoder.layers.self_attention_1.query.kernel take: 0.001s\n",
      "k: decoder.layers.self_attention_1.value.kernel take: 0.001s\n",
      "k: decoder.layers.self_attention_2.AttentionOp_0.dyn_w_proj.dd.kernel take: 0.001s\n",
      "k: decoder.layers.self_attention_2.AttentionOp_0.dyn_w_proj.dw1.kernel take: 0.001s\n",
      "k: decoder.layers.self_attention_2.AttentionOp_0.dyn_w_proj.qkw take: 0.001s\n",
      "k: decoder.layers.self_attention_2.k_norm.scale take: 0.001s\n",
      "k: decoder.layers.self_attention_2.key.kernel take: 0.001s\n",
      "k: decoder.layers.self_attention_2.out.kernel take: 0.001s\n",
      "k: decoder.layers.self_attention_2.q_norm.scale take: 0.001s\n",
      "k: decoder.layers.self_attention_2.query.kernel take: 0.001s\n",
      "k: decoder.layers.self_attention_2.value.kernel take: 0.001s\n",
      "k: decoder.layers.self_attention_3.AttentionOp_0.dyn_w_proj.dd.kernel take: 0.001s\n",
      "k: decoder.layers.self_attention_3.AttentionOp_0.dyn_w_proj.dw1.kernel take: 0.001s\n",
      "k: decoder.layers.self_attention_3.AttentionOp_0.dyn_w_proj.qkw take: 0.001s\n",
      "k: decoder.layers.self_attention_3.k_norm.scale take: 0.001s\n",
      "k: decoder.layers.self_attention_3.key.kernel take: 0.001s\n",
      "k: decoder.layers.self_attention_3.out.kernel take: 0.001s\n",
      "k: decoder.layers.self_attention_3.q_norm.scale take: 0.001s\n",
      "k: decoder.layers.self_attention_3.query.kernel take: 0.001s\n",
      "k: decoder.layers.self_attention_3.value.kernel take: 0.001s\n",
      "k: decoder.logits_dense.kernel take: 0.001s\n",
      "k: token_embedder.embedding take: 0.001s\n"
     ]
    }
   ],
   "source": [
    "## moe部分的参数保存，保存后在bucket后台人工进行转移\n",
    "start_time = time.time()\n",
    "unshared_experts = 44\n",
    "\n",
    "scale = 1\n",
    "mlp_dim = 5632 // scale\n",
    "model_dim = 4096 // scale\n",
    "copy_dim = 128 // scale\n",
    "copy_expert_dim = mlp_dim // unshared_experts\n",
    "# fp16_dtype = np.dtype('float16')\n",
    "# 4个子层\n",
    "total_moe_params = [{} for i in range(4)]\n",
    "for k, v in xm3p5_w.items():\n",
    "    v = jnp.array(v).astype(jnp.bfloat16)\n",
    "    print(f'k: {k} take: {time.time() - start_time:.3f}s')\n",
    "    if 'decoder.layers.mlp_' in k:\n",
    "        mlp_inx = k.find('mlp_')\n",
    "        l = k[mlp_inx+4: mlp_inx+5]\n",
    "        if int(l) in [2, 3]:\n",
    "            continue\n",
    "        if int(l) % 2 != 0: continue\n",
    "        moe_params = total_moe_params[int(l)]\n",
    "        unshared_mlp = k.replace('decoder.layers.mlp_', 'decoder.layers.unshared_mlp_')\n",
    "        if 'mgate' in unshared_mlp:\n",
    "            moe_params[unshared_mlp] = v\n",
    "            continue\n",
    "        unshared_mlp = unshared_mlp.replace('.kernel', '')\n",
    "        v = v.transpose(1, 0, 2)\n",
    "        # unshared: 44 * 12 * model_dim * mlp_dim,  mlp: model_dim * 12 * mlp_dim\n",
    "        unshared_mlp_w = []\n",
    "        if '.wo.' in k:\n",
    "            copy_w = v.reshape(12, 44, 1, copy_dim, model_dim).repeat(44, 2).reshape(12, 44, -1, model_dim).transpose(1, 0, 2, 3)\n",
    "        else:\n",
    "            copy_w = v.reshape(12, model_dim, 44, 1, copy_dim).repeat(44, 3).reshape(12, model_dim, 44, -1).transpose(2, 0, 1, 3)\n",
    "        v = v[None] # extend dim\n",
    "        init_w = (copy_w + v) / 2\n",
    "        print(f'copy_w: {copy_w.shape} copy_w: {copy_w.dtype} init_w: {init_w.dtype} unshared_mlp: {unshared_mlp}')\n",
    "        moe_params[unshared_mlp] = init_w\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091adcea-e891-48be-a487-4129101e5446",
   "metadata": {},
   "source": [
    "# 分批保存模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c258ff8-11aa-4b1c-84c4-aee37739e818",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Configured `CheckpointManager` using deprecated legacy API. Please follow the instructions at https://orbax.readthedocs.io/en/latest/api_refactor.html to migrate by August 1st, 2024.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, params in enumerate(total_moe_params):\n",
    "    if not params: continue\n",
    "    print(params.keys(), '\\n')\n",
    "    save_moe_params = {}\n",
    "    for k, v in params.items():\n",
    "        newk = tuple(k.split('.'))\n",
    "        save_moe_params[newk] = v\n",
    "    print(f'Save step: {i+1}')\n",
    "    save_params(i + 1, save_dir, save_moe_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09edd2b3-fa6d-49d0-9884-2c00792a60eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _METADATA, checkpoint三个文件转移到实际保存的checkpoint文件夹中进行替换\n",
    "start_time = time.time()\n",
    "unshared_experts = 44\n",
    "mlp_dim = 5632 // scale\n",
    "copy_expert_dim = mlp_dim // unshared_experts\n",
    "moe_params = {}\n",
    "for k, v in xm3p5_w.items():\n",
    "    v = jnp.array([100]).astype(jnp.bfloat16)\n",
    "    print(f'k: {k} take: {time.time() - start_time:.3f}s')\n",
    "    if 'mgate' not in k:\n",
    "        moe_params[k] = v\n",
    "    if 'decoder.layers.mlp_' in k:\n",
    "        mlp_inx = k.find('mlp_')\n",
    "        l = k[mlp_inx+4: mlp_inx+5]\n",
    "        if int(l) % 2 != 0: continue\n",
    "        unshared_mlp = k.replace('decoder.layers.mlp_', 'decoder.layers.unshared_mlp_')\n",
    "        # mgate需要.kernel, moe不需要，因为moe的参数采用的是self.params创建的，而mgate是采用flax的DenseGeneral\n",
    "        if 'mgate' not in unshared_mlp:\n",
    "            unshared_mlp = unshared_mlp.replace('.kernel', '')\n",
    "        moe_params[unshared_mlp] = v\n",
    "\n",
    "moe_params = {tuple(k.split('.')): v for k,v in moe_params.items()}\n",
    "save_params(5, save_dir, moe_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18042ec2-513e-49a0-ad93-4850650763bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# save_dir1 = str(save_dir).rstrip('/')\n",
    "source_dir = 'gs://llm_base_models_us-east5/v5p_256/7B/xm_45x7B_moe_0922/checkpoints'\n",
    "target_dir = 'gs://llm_base_models_us-east5/v5p_256/7B/xm_45x7B_moe_0922/checkpoints'\n",
    "source_step = 5\n",
    "command = f'gsutil cp {source_dir}/{source_step}/state/_METADATA {target_dir}/0/state/ '\n",
    "r = subprocess.run(command, stdout=subprocess.PIPE, shell=True)\n",
    "\n",
    "command = f'gsutil cp {source_dir}/{source_step}/state/checkpoint {target_dir}/0/state/ '\n",
    "r = subprocess.run(command, stdout=subprocess.PIPE, shell=True)\n",
    "\n",
    "# command = f'gsutil cp {source_dir}/{source_step}/state/_sharding {target_dir}/0/state/ '\n",
    "# r = subprocess.run(command, stdout=subprocess.PIPE, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a75068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基于tpu type 构建_sharding文件\n",
    "'''\n",
    "_sharding文件格式如下：\n",
    "{\n",
    "  b3B0X3N0YXRlLm11LnBhcmFtcy50b2tlbl9lbWJlZGRlci5lbWJlZGRpbmc=': {'sharding_type': 'NamedSharding',\n",
    "  'shape': [1, 1, 4, 1, 1, 1, 1],\n",
    "  'axis_names': ['data', 'stage', 'fsdp', 'fsdp_transpose', 'sequence', 'tensor','autoregressive'],\n",
    "  'partition_spec': [['tensor', 'autoregressive'], ['fsdp', 'fsdp_transpose', 'sequence']],\n",
    "   2: 4},\n",
    "   ...\n",
    "   }\n",
    "   '''\n",
    "# moe sharding\n",
    "_sharding_path = 'gs://llm_base_models_us-east5/v5p_256/7B/xm3p5_moe_params_no_opt_v5p_64_sharding'\n",
    "_sharding_path = epath.Path(_sharding_path)\n",
    "# 读取已有的_sharding文件\n",
    "with _sharding_path.open('r') as f:\n",
    "    _sharding = json.load(f)\n",
    "\n",
    "tpu_type = 'v5p-64'\n",
    "core_nums = int(tpu_type.split('-')[-1])\n",
    "if 'v3' not in tpu_type:\n",
    "    core_nums = core_nums // 2\n",
    "print(f'core_nums: {core_nums}')\n",
    "updated_sharding = {}\n",
    "for k, v in _sharding.items():\n",
    "    v = json.loads(v)\n",
    "    v['shape'][2] = core_nums\n",
    "    updated_sharding[k] = json.dumps(v)\n",
    "    \n",
    "updated_sharding_path = f'{save_dir}/0/state/_sharding'\n",
    "\n",
    "updated_sharding_path = epath.Path(updated_sharding_path)\n",
    "with updated_sharding_path.open('w') as f:\n",
    "    json.dump(updated_sharding, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1626fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import base64\n",
    "\n",
    "# def decode_base64(encoded_str):\n",
    "#     decoded_bytes = base64.b64decode(encoded_str)\n",
    "#     decoded_str = decoded_bytes.decode('utf-8')\n",
    "#     return decoded_str\n",
    "    \n",
    "# for k, v in _sharding.items():\n",
    "#     decode_k = decode_base64(k)\n",
    "#     if 'opt_state' in decode_k or 'step' in decode_k: continue\n",
    "#     print(decode_k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
