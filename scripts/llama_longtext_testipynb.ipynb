{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96b01a63-40b8-41fa-9883-ff8371f580b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPECIAL_TOKENS: ((151643, '<|endoftext|>'), (151644, '<|im_start|>'), (151645, '<|im_end|>'), (151646, '<|extra_0|>'), (151647, '<|extra_1|>'), (151648, '<|extra_2|>'), (151649, '<|extra_3|>'), (151650, '<|extra_4|>'), (151651, '<|extra_5|>'), (151652, '<|extra_6|>'), (151653, '<|extra_7|>'), (151654, '<|extra_8|>'), (151655, '<|extra_9|>'), (151656, '<|extra_10|>'), (151657, '<|extra_11|>'), (151658, '<|extra_12|>'), (151659, '<|extra_13|>'), (151660, '<|extra_14|>'), (151661, '<|extra_15|>'), (151662, '<|extra_16|>'), (151663, '<|extra_17|>'), (151664, '<|extra_18|>'), (151665, '<|extra_19|>'), (151666, '<|extra_20|>'), (151667, '<|extra_21|>'), (151668, '<|extra_22|>'), (151669, '<|extra_23|>'), (151670, '<|extra_24|>'), (151671, '<|extra_25|>'), (151672, '<|extra_26|>'), (151673, '<|extra_27|>'), (151674, '<|extra_28|>'), (151675, '<|extra_29|>'), (151676, '<|extra_30|>'), (151677, '<|extra_31|>'), (151678, '<|extra_32|>'), (151679, '<|extra_33|>'), (151680, '<|extra_34|>'), (151681, '<|extra_35|>'), (151682, '<|extra_36|>'), (151683, '<|extra_37|>'), (151684, '<|extra_38|>'), (151685, '<|extra_39|>'), (151686, '<|extra_40|>'), (151687, '<|extra_41|>'), (151688, '<|extra_42|>'), (151689, '<|extra_43|>'), (151690, '<|extra_44|>'), (151691, '<|extra_45|>'), (151692, '<|extra_46|>'), (151693, '<|extra_47|>'), (151694, '<|extra_48|>'), (151695, '<|extra_49|>'), (151696, '<|extra_50|>'), (151697, '<|extra_51|>'), (151698, '<|extra_52|>'), (151699, '<|extra_53|>'), (151700, '<|extra_54|>'), (151701, '<|extra_55|>'), (151702, '<|extra_56|>'), (151703, '<|extra_57|>'), (151704, '<|extra_58|>'), (151705, '<|extra_59|>'), (151706, '<|extra_60|>'), (151707, '<|extra_61|>'), (151708, '<|extra_62|>'), (151709, '<|extra_63|>'), (151710, '<|extra_64|>'), (151711, '<|extra_65|>'), (151712, '<|extra_66|>'), (151713, '<|extra_67|>'), (151714, '<|extra_68|>'), (151715, '<|extra_69|>'), (151716, '<|extra_70|>'), (151717, '<|extra_71|>'), (151718, '<|extra_72|>'), (151719, '<|extra_73|>'), (151720, '<|extra_74|>'), (151721, '<|extra_75|>'), (151722, '<|extra_76|>'), (151723, '<|extra_77|>'), (151724, '<|extra_78|>'), (151725, '<|extra_79|>'), (151726, '<|extra_80|>'), (151727, '<|extra_81|>'), (151728, '<|extra_82|>'), (151729, '<|extra_83|>'), (151730, '<|extra_84|>'), (151731, '<|extra_85|>'), (151732, '<|extra_86|>'), (151733, '<|extra_87|>'), (151734, '<|extra_88|>'), (151735, '<|extra_89|>'), (151736, '<|extra_90|>'), (151737, '<|extra_91|>'), (151738, '<|extra_92|>'), (151739, '<|extra_93|>'), (151740, '<|extra_94|>'), (151741, '<|extra_95|>'), (151742, '<|extra_96|>'), (151743, '<|extra_97|>'), (151744, '<|extra_98|>'), (151745, '<|extra_99|>'), (151746, '<|extra_100|>'), (151747, '<|extra_101|>'), (151748, '<|extra_102|>'), (151749, '<|extra_103|>'), (151750, '<|extra_104|>'), (151751, '<|extra_105|>'), (151752, '<|extra_106|>'), (151753, '<|extra_107|>'), (151754, '<|extra_108|>'), (151755, '<|extra_109|>'), (151756, '<|extra_110|>'), (151757, '<|extra_111|>'), (151758, '<|extra_112|>'), (151759, '<|extra_113|>'), (151760, '<|extra_114|>'), (151761, '<|extra_115|>'), (151762, '<|extra_116|>'), (151763, '<|extra_117|>'), (151764, '<|extra_118|>'), (151765, '<|extra_119|>'), (151766, '<|extra_120|>'), (151767, '<|extra_121|>'), (151768, '<|extra_122|>'), (151769, '<|extra_123|>'), (151770, '<|extra_124|>'), (151771, '<|extra_125|>'), (151772, '<|extra_126|>'), (151773, '<|extra_127|>'), (151774, '<|extra_128|>'), (151775, '<|extra_129|>'), (151776, '<|extra_130|>'), (151777, '<|extra_131|>'), (151778, '<|extra_132|>'), (151779, '<|extra_133|>'), (151780, '<|extra_134|>'), (151781, '<|extra_135|>'), (151782, '<|extra_136|>'), (151783, '<|extra_137|>'), (151784, '<|extra_138|>'), (151785, '<|extra_139|>'), (151786, '<|extra_140|>'), (151787, '<|extra_141|>'), (151788, '<|extra_142|>'), (151789, '<|extra_143|>'), (151790, '<|extra_144|>'), (151791, '<|extra_145|>'), (151792, '<|extra_146|>'), (151793, '<|extra_147|>'), (151794, '<|extra_148|>'), (151795, '<|extra_149|>'), (151796, '<|extra_150|>'), (151797, '<|extra_151|>'), (151798, '<|extra_152|>'), (151799, '<|extra_153|>'), (151800, '<|extra_154|>'), (151801, '<|extra_155|>'), (151802, '<|extra_156|>'), (151803, '<|extra_157|>'), (151804, '<|extra_158|>'), (151805, '<|extra_159|>'), (151806, '<|extra_160|>'), (151807, '<|extra_161|>'), (151808, '<|extra_162|>'), (151809, '<|extra_163|>'), (151810, '<|extra_164|>'), (151811, '<|extra_165|>'), (151812, '<|extra_166|>'), (151813, '<|extra_167|>'), (151814, '<|extra_168|>'), (151815, '<|extra_169|>'), (151816, '<|extra_170|>'), (151817, '<|extra_171|>'), (151818, '<|extra_172|>'), (151819, '<|extra_173|>'), (151820, '<|extra_174|>'), (151821, '<|extra_175|>'), (151822, '<|extra_176|>'), (151823, '<|extra_177|>'), (151824, '<|extra_178|>'), (151825, '<|extra_179|>'), (151826, '<|extra_180|>'), (151827, '<|extra_181|>'), (151828, '<|extra_182|>'), (151829, '<|extra_183|>'), (151830, '<|extra_184|>'), (151831, '<|extra_185|>'), (151832, '<|extra_186|>'), (151833, '<|extra_187|>'), (151834, '<|extra_188|>'), (151835, '<|extra_189|>'), (151836, '<|extra_190|>'), (151837, '<|extra_191|>'), (151838, '<|extra_192|>'), (151839, '<|extra_193|>'), (151840, '<|extra_194|>'), (151841, '<|extra_195|>'), (151842, '<|extra_196|>'), (151843, '<|extra_197|>'), (151844, '<|extra_198|>'), (151845, '<|extra_199|>'), (151846, '<|extra_200|>'), (151847, '<|extra_201|>'), (151848, '<|extra_202|>'), (151849, '<|extra_203|>'), (151850, '<|extra_204|>'))\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import LlamaForCausalLM\n",
    "import torch\n",
    "\n",
    "TOKENIZER_PATH =  '/home/lishengping/mengqy/projects/slim_alignment/tokenizer'\n",
    "qwen_tokenizer = AutoTokenizer.from_pretrained(\n",
    "            TOKENIZER_PATH, use_fast=False, trust_remote_code=True\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d079f024-2ad6-4d8d-ac27-2f0871d0323c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb39a29c6184473fbc0f2c509349b821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You set `add_prefix_space`. The tokenizer needs to be converted from the slow tokenizers\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaSdpaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (rotary_emb): LlamaRotaryEmbedding()\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm()\n",
       "        (post_attention_layernorm): LlamaRMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir = '/home/lishengping/mengqy/data/llama_model/llama-7b-hf-custom'\n",
    "device = 'cuda:1'\n",
    "llama_model = LlamaForCausalLM.from_pretrained(model_dir, device_map='cpu')\n",
    "model_dir = '/home/lishengping/mengqy/data/llama_model/llama-7b-hf-custom'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "llama_model = llama_model.half()\n",
    "llama_model = llama_model.to(device)\n",
    "llama_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1721d1e-d741-4d42-8f93-998836e54847",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-19 09:23:09.386769: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/lib/x86_64-linux-gnu/:/opt/conda/lib\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example[name]: Tensor(\"strided_slice:0\", shape=(None,), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-19 09:23:11.177845: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/lib/x86_64-linux-gnu/:/opt/conda/lib\n",
      "2024-07-19 09:23:11.177950: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/lib/x86_64-linux-gnu/:/opt/conda/lib\n",
      "2024-07-19 09:23:11.178016: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/lib/x86_64-linux-gnu/:/opt/conda/lib\n",
      "2024-07-19 09:23:11.178077: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/lib/x86_64-linux-gnu/:/opt/conda/lib\n",
      "2024-07-19 09:23:11.179013: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/lib/x86_64-linux-gnu/:/opt/conda/lib\n",
      "2024-07-19 09:23:11.179063: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import argparse\n",
    "import socket\n",
    "import random\n",
    "from collections import defaultdict\n",
    "os.environ[\"JAX_PLATFORMS\"] = \"cpu\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import jax\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "seq_len = 32769\n",
    "\n",
    "def _parse_function(example_proto):\n",
    "    # seq_len = 1024\n",
    "    feature_desc = {key: tf.io.VarLenFeature(tf.int64) for key in task_features}\n",
    "    example = tf.io.parse_single_example(example_proto, feature_desc)\n",
    "    for name in list(example.keys()):\n",
    "        t = example[name]\n",
    "        if t.dtype == tf.int64:\n",
    "            t = tf.cast(t, dtype=tf.int32)\n",
    "        # example[name] = tf.sparse.to_dense(t, default_value=0)[: 2 * seq_len - 2]\n",
    "        # example[name] = tf.reshape(example[name], [2, seq_len - 1])\n",
    "        # t = tf.constant([[10], [10]], dtype=tf.int32)\n",
    "        # example[name] = tf.concat([t, example[name]], 1)\n",
    "        example[name] = tf.sparse.to_dense(t, default_value=0)[: seq_len]\n",
    "        print(f'example[name]: {example[name]}')\n",
    "    return example\n",
    "\n",
    "task_features = {'input_ids': None}\n",
    "train_seed = 1234\n",
    "num_infeed_hosts = 1\n",
    "shuffle_buffer_size = None\n",
    "pad_id = 0\n",
    "batch_size = 1\n",
    "\n",
    "fname = ['gs://jax_llm_data_us-east5/xiaomeng/v3.5/tfids_4k_32k_0622/B009/F009/000.long']\n",
    "# fname = ['gs://jax_llm_data_us-east5/xiaomeng/v3.5/tfids_4k_32k_0622/valid_tfrecord/001.long']\n",
    "# fname = ['gs://jax_llm_data/xiaomeng/sft_target/tfrecord_len2k/en.test.continue_write.tfrecord']\n",
    "tf.random.set_seed(train_seed)\n",
    "ds = tf.data.Dataset.from_tensor_slices(fname)\n",
    "ds = ds.apply(tf.data.TFRecordDataset)\n",
    "# shard host data\n",
    "# ds = ds.shard(num_infeed_hosts, 0)\n",
    "ds = ds.map(_parse_function, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "if shuffle_buffer_size is not None:\n",
    "    ds = ds.shuffle(buffer_size=self.shuffle_buffer_size)\n",
    "padded_shapes = {key: seq_len for key in task_features}\n",
    "padding_values = {key: pad_id for key in task_features}\n",
    "ds = ds.padded_batch(\n",
    "    batch_size=np.prod(batch_size),\n",
    "    padded_shapes=padded_shapes,\n",
    "    padding_values=padding_values,\n",
    "    drop_remainder=True,\n",
    ")\n",
    "# ds = ds.map(self.convert)\n",
    "# ds = ds.prefetch(tf.data.AUTOTUNE)\n",
    "iter_ds = ds.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85b3a8ce-2feb-427c-bfc4-20fe0ccb049f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: 0/1000, take: 2.797s\n",
      "Processing: 1/1000, take: 3.599s\n",
      "Processing: 2/1000, take: 4.400s\n",
      "Processing: 3/1000, take: 5.214s\n",
      "Processing: 4/1000, take: 6.017s\n",
      "Processing: 5/1000, take: 7.678s\n",
      "Processing: 6/1000, take: 9.319s\n",
      "Processing: 7/1000, take: 10.875s\n",
      "Processing: 8/1000, take: 12.489s\n",
      "Processing: 9/1000, take: 13.174s\n"
     ]
    }
   ],
   "source": [
    "# text = ''''In a world brimming with heartwarming stories, few are as touching and inspiring as those of adoption. These tales are a testament to the extraordinary power of love, compassion, and the unbreakable bonds that form when individuals open their hearts to welcome a child into their lives. Join us on this heartwarming journey as we explore how adoption transforms strangers into loving families, and let the hope and inspiration they bring warm your heart. \n",
    "# A Journey of Love\n",
    "\n",
    "# Adoption is more than a legal process; it's a profound journey of love. It's the story of parents, often complete strangers to a child, who make a conscious choice to love, nurture, and provide a forever home to a little one in need. It's a commitment that transcends biology, built upon the foundation of selflessness and boundless love. \n",
    "\n",
    "\n",
    "# 1.The Miracle of Matching\n",
    "\n",
    "# The process of adoption can be a complex one, involving home studies, interviews, and legal procedures. However, amid the paperwork and formalities, there's a remarkable moment of magic when a child is matched with their forever family. It's a moment filled with hope and anticipation, the beginning of a new chapter in the lives of both child and parent. \n",
    "\n",
    "\n",
    "# The day of adoption finalization is a joyous occasion, marking the official start of a lifelong journey together. The child finds their forever family, and the parents find their missing piece. From that day forward, an unbreakable bond is forged, one that grows stronger with each passing day, filled with love, laughter, and shared experiences. '''\n",
    "start = time.time()\n",
    "N = 10\n",
    "with torch.no_grad():\n",
    "    for i in range(N):\n",
    "        long_sample = next(iter_ds)\n",
    "        qwen_input_ids = long_sample['input_ids']\n",
    "        qwen_text = qwen_tokenizer.decode(qwen_input_ids[0, :8000])\n",
    "        text = qwen_text\n",
    "        input_ids = tokenizer.encode(text, return_tensors='pt')\n",
    "        if input_ids.device.type == 'cpu':\n",
    "            input_ids = input_ids.to(device)\n",
    "        result = llama_model(input_ids[:, :], labels=input_ids[:, :])\n",
    "        save_dict = {'text': text, 'input_ids': input_ids, 'loss': result.loss.cpu()}\n",
    "        pickle.dump(save_dict, open('llama2-7b.long.eval.1k.pkl', 'ab'))\n",
    "        print(f'Processing: {i}/1000, take: {time.time() - start:.3f}s')\n",
    "        del result\n",
    "        del input_ids\n",
    "        del save_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a8b796-737e-46de-8e2c-6b4223d8c940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f05f6c-75a0-4a51-b803-ebbb2dc93c90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
