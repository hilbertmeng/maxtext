{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yaml\n",
    "import json\n",
    "import base64\n",
    "from collections import defaultdict\n",
    "from typing import Tuple\n",
    "import functools\n",
    "\n",
    "sys.path.append('/home/lishengping/projects/maxtext/MaxText')\n",
    "os.environ['HARDWARE'] = 'tpu'\n",
    "\n",
    "from layers import models\n",
    "import max_utils\n",
    "import jax\n",
    "import orbax\n",
    "import jax.numpy as jnp\n",
    "from jax.sharding import Mesh\n",
    "from flax.traverse_util import flatten_dict, unflatten_dict\n",
    "from flax import linen as nn\n",
    "from transformers import AutoTokenizer\n",
    "from etils import epath\n",
    "import orbax.checkpoint as ocp\n",
    "\n",
    "import pyconfig\n",
    "from jax.sharding import PartitionSpec\n",
    "from flax.linen import partitioning as nn_partitioning\n",
    "\n",
    "\n",
    "TOKENIZER_PATH = '/home/lishengping/tokenizer'\n",
    "if not os.path.exists(TOKENIZER_PATH):\n",
    "    !gsutil cp -r gs://llm_base_models_us-east5/qwen/tokenizer /home/lishengping/\n",
    "tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH, use_fast=True, trust_remote_code=True)\n",
    "\n",
    "read_dir = \"gs://llm_base_models_europe-west4/v5p_256/7B/PileDCSlimLlama7B32Kx4x256x1v5p_0713/checkpoints\"\n",
    "read_dir = 'gs://llm_base_models_europe-west4/v5p_256/7B/xm3.5-7b-chat-v6/checkpoints/'\n",
    "read_dir = 'gs://llm_base_models_europe-west4/v5p_256/7B/xm3.5-7b-chat-v7/checkpoints/'\n",
    "\n",
    "# read_dir = 'gs://llm_base_models_europe-west4/v5p_256/7B/dense_continue_1209/checkpoints'\n",
    "# read_dir = \"gs://llm_base_models_europe-west4/v5p_256/7B/test\"\n",
    "\n",
    "read_dir = epath.Path(read_dir)\n",
    "\n",
    "config_name = '/home/lishengping/projects/maxtext/MaxText/configs/dc_8x7b_moe.yml'\n",
    "\n",
    "argv = [None, config_name]\n",
    "pyconfig.initialize(argv)\n",
    "config = pyconfig.config\n",
    "# validate_train_config(config)\n",
    "devices_array = max_utils.create_device_mesh(config)\n",
    "mesh = Mesh(devices_array, config.mesh_axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def decode_base64(encoded_str):\n",
    "    decoded_bytes = base64.b64decode(encoded_str)\n",
    "    decoded_str = decoded_bytes.decode('utf-8')\n",
    "    return decoded_str\n",
    "\n",
    "\n",
    "def mesh_shard_rules(mesh, rules, remove_keys=[]):\n",
    "    _sharding_dict = {}\n",
    "    for name, rule in rules.items():\n",
    "        if isinstance(rule, str):\n",
    "            rule = json.loads(rule)\n",
    "        name = decode_base64(name)\n",
    "        param_key = tuple(name.split('.'))\n",
    "        remove = any([1 if key in param_key else 0 for key in remove_keys])\n",
    "        if remove: continue\n",
    "        prule = [tuple(r) if isinstance(r, list) else r for r in rule['partition_spec'] ]\n",
    "        spec = jax.sharding.PartitionSpec(*prule)\n",
    "        _sharding_dict[param_key] = jax.sharding.NamedSharding(mesh, spec)\n",
    "    return _sharding_dict\n",
    "\n",
    "\n",
    "def rewrite_bucket_sharding(mesh, old_sharding, save_path):\n",
    "    cur_machine_sharding = {}\n",
    "    for k, v in old_sharding.items():\n",
    "        if isinstance(v, str):\n",
    "            v = json.loads(v)\n",
    "        v['shape'] = mesh.device_ids.shape\n",
    "        cur_machine_sharding[k] = v\n",
    "    save_path = epath.Path(save_path)\n",
    "    with save_path.open('w') as f:\n",
    "        json.dump(cur_machine_sharding, f)\n",
    "    \n",
    "# mesh length is 8\n",
    "_sharding_path = 'gs://llm_base_models_europe-west4/v5p_256/7B/xm3p5_7b_sharding'\n",
    "# dense\n",
    "_sharding_path = 'gs://llm_base_models_europe-west4/v5p_256/7B/xm3.5-7b-chat-v6/checkpoints/451600/state/_sharding'\n",
    "# moe with unshare\n",
    "# _sharding_path = 'gs://llm_base_models_europe-west4/v5p_256/7B/xm3p5_7b_with_perlayer_moe_sharding'\n",
    "_sharding_path = epath.Path(_sharding_path)\n",
    "\n",
    "# remove_keys = ['opt_state', 'step']\n",
    "remove_keys = []\n",
    "with _sharding_path.open('r') as f:\n",
    "    _sharding_rules = json.load(f)\n",
    "_sharding_dict = mesh_shard_rules(mesh, _sharding_rules, remove_keys=remove_keys)\n",
    "_sharding_dict = unflatten_dict(_sharding_dict)\n",
    "restore_args = {}\n",
    "weight_dtype = jnp.bfloat16\n",
    "for k, v in flatten_dict(_sharding_dict).items():\n",
    "    joink = '.'.join(k)\n",
    "    if 'unshare' in joink: continue\n",
    "    restore_args[k] =  ocp.ArrayRestoreArgs(restore_type=jax.Array, dtype=weight_dtype, sharding=v)\n",
    "for k, v in restore_args.items():\n",
    "    print(k)\n",
    "restore_args = unflatten_dict(restore_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# load\n",
    "read_dir = 'gs://llm_base_models_europe-west4/v5p_256/7B/PileDCSlimLlama7B32Kx4x256x1v5p_0713/checkpoints/440000/state'\n",
    "read_dir = 'gs://llm_base_models_us-east5/v5p_256/7B/xm3.5-7b-chat-v1/checkpoints/450000/state'\n",
    "read_dir = 'gs://llm_base_models_us-east5/v5p_256/7B/xm3.5-7b-chat-v2/checkpoints/453200/state'\n",
    "read_dir = 'gs://llm_base_models_us-east5/v5p_256/7B/xm3.5-7b-chat-v3/checkpoints/453200/state'\n",
    "read_dir = 'gs://llm_base_models_us-east5/v5p_256/7B/xm3.5-7b-chat-v4/checkpoints/451000/state'\n",
    "read_dir = 'gs://llm_base_models_us-east5/v5p_256/7B/xm3.5-7b-chat-v5/checkpoints/450800/state'\n",
    "read_dir = 'gs://llm_base_models_us-central2/v5p_256/7B/PileDCSlimLlama7B4Kx4x256x1v5p/checkpoints/checkpoint_00100000/state'\n",
    "read_dir = epath.Path(read_dir)\n",
    "use_ocdbt = False\n",
    "ckptr = ocp.Checkpointer(ocp.PyTreeCheckpointHandler(use_ocdbt=use_ocdbt))\n",
    "# restore_args: 结构必须和模型结构一致\n",
    "if use_ocdbt:\n",
    "    state = ckptr.restore(read_dir, args=ocp.args.PyTreeRestore(restore_args=restore_args))\n",
    "else:\n",
    "    state = ckptr.restore(read_dir)\n",
    "params = {'params': state['params']}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "ffn_params = {}\n",
    "for k, v in flatten_dict(params).items():\n",
    "    joink = '.'.join(k)\n",
    "    if 'layers.mlp' in joink:\n",
    "        ffn_params[k] = v\n",
    "    print(joink)\n",
    "print(len(ffn_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# save\n",
    "# xm3.5-7b-chat-v6: 0\n",
    "# xm3.5-7b-chat-v7: 1\n",
    "# PileDCSlimLlama7B32Kx4x256x1v5p_0713: 440000: 2\n",
    "# xm3.5-7b-chat-v1: 3\n",
    "# xm3.5-7b-chat-v2: 4\n",
    "# xm3.5-7b-chat-v3: 5\n",
    "# xm3.5-7b-chat-v4: 6\n",
    "# xm3.5-7b-chat-v5: 7\n",
    "# 下面的转不了，是pax格式\n",
    "# PileDCSlimLlama7B32Kx4x256x1v5p: 100000: 8\n",
    "# PileDCSlimLlama7B32Kx4x256x1v5p: 200000: 9\n",
    "# PileDCSlimLlama7B32Kx4x256x1v5p: 300000: 10\n",
    "# PileDCSlimLlama7B32Kx4x256x1v5p: 400000: 11\n",
    "save_step = 8\n",
    "save_dir = \"gs://llm_base_models_europe-west4/v5p_256/7B/moe_ffn_init_base_multi_dmodels_1210/checkpoints\"\n",
    "save_dir = epath.Path(save_dir)\n",
    "item = {\n",
    "    \"state\": orbax.checkpoint.Checkpointer(orbax.checkpoint.PyTreeCheckpointHandler(use_ocdbt=False))\n",
    "}\n",
    "save_params = unflatten_dict(ffn_params)\n",
    "assert 'params' not in save_params['params']['params']\n",
    "max_mngr = orbax.checkpoint.CheckpointManager(save_dir, item)\n",
    "max_mngr.save(save_step, {'state': save_params})"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
