{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f980aa82-c2bc-4501-b0b2-8635af06a8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "396e9ac1-5eb9-4d3c-9f34-ce37f9868c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "# !pip install smart_open\n",
    "# !pip install orbax-checkpoint==0.2.6\n",
    "\n",
    "os.environ[\"JAX_PLATFORMS\"] = \"cpu\"\n",
    "import smart_open\n",
    "import numpy as np\n",
    "import jax\n",
    "import orbax\n",
    "import orbax.checkpoint\n",
    "from etils import epath\n",
    "from flax.traverse_util import flatten_dict, unflatten_dict\n",
    "from jax import ShapeDtypeStruct\n",
    "\n",
    "# orbax-checkpoint=0.2.6需要修改下下面的代码: 将jax.config.jax_coordination_service去掉\n",
    "# ~/miniconda3/lib/python3.10/site-packages/orbax/checkpoint/checkpoint_manager.py:334, in CheckpointManager.reached_preemption(self, step)\n",
    "#     331 def reached_preemption(self, step: int) -> bool:\n",
    "#     332   \"\"\"Returns True if a preemption sync point has been reached.\"\"\"\n",
    "#     333   return (\n",
    "# --> 334       jax.config.jax_coordination_service\n",
    "#     335       and multihost_utils.reached_preemption_sync_point(step)\n",
    "#     336   )\n",
    "\n",
    "# AttributeError: 'Config' object has no attribute 'jax_coordination_service'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe6908c3-e821-41b0-9a01-8e50cfca449d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-05 03:15:27.159807: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint_name: checkpoint_00440000\n",
      "metadata_path: gs://llm_base_models_us-central2/v5p_256/7B/PileDCSlimLlama7B4Kx4x256x1v5p/checkpoints/checkpoint_00440000/metadata/metadata\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:absl:Checkpoint structure file does not exist at gs://llm_base_models_us-central2/v5p_256/7B/PileDCSlimLlama7B4Kx4x256x1v5p/checkpoints/checkpoint_00440000/state. Attempting to assume an implicit tree structure.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1720149371.532901   21765 gcs_resource.cc:109] Using default AdmissionQueue with limit 32\n",
      "I0000 00:00:1720149371.537039   22912 google_auth_provider.cc:180] Running on GCE, using service account 887571727717-compute@developer.gserviceaccount.com\n"
     ]
    }
   ],
   "source": [
    "# no_prefix_2  : no_prefix元祖的第2个位置 \n",
    "# m, v   <=> mdl_vars \n",
    "# p#12#i-1_2  : p#12#i-1元祖的第2个位置\n",
    "# m, v\n",
    "# opt 结构\n",
    "# [{\n",
    "# no_prefix: (count, count, count+mv, count)\n",
    "# p#12#i-1: (count, count, count+mv, count)\n",
    "# }]\n",
    "# 最后一个count的shape 为 layer_num\n",
    "\n",
    "# 构造mdl_vars和opt_states的shapedtype\n",
    "layer_num = 48\n",
    "sub_layer_num = 4\n",
    "read_dir = \"gs://llm_base_models_us-central2/v5p_256/7B/PileDCSlimLlama7B4Kx4x256x1v5p/checkpoints/\"\n",
    "# read_dir = \"gs://llm_base_models/maxtext_align_pax_dc/PileDCSlimLlama7B32Kx4x256x1Align4/checkpoints/\"\n",
    "load_step = 440000\n",
    "\n",
    "step_prefix = \"checkpoint\"\n",
    "step_format_fixed_length = 8\n",
    "options = orbax.checkpoint.CheckpointManagerOptions(step_prefix=step_prefix, step_format_fixed_length=step_format_fixed_length)\n",
    "item = {\"state\": orbax.checkpoint.Checkpointer(orbax.checkpoint.PyTreeCheckpointHandler(use_ocdbt=False))}\n",
    "pax_mngr = orbax.checkpoint.CheckpointManager(read_dir, item, options)\n",
    "\n",
    "step_prefix = 'checkpoint'\n",
    "checkpoint_name = f\"{step_prefix}_\" + str(load_step).zfill(step_format_fixed_length)\n",
    "print(f\"checkpoint_name: {checkpoint_name}\")\n",
    "metadata_path = os.path.join(read_dir, checkpoint_name, \"metadata/metadata\")\n",
    "print(f\"metadata_path: {metadata_path}\")\n",
    "\n",
    "with smart_open.open(metadata_path, \"r\") as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "flat_metadata = flatten_dict(metadata[\"train_state_metadata\"])\n",
    "unpadded_global_shapes = defaultdict(dict)\n",
    "for k, v in flat_metadata.items():\n",
    "    param_key, shape_dtype = k[:-1], k[-1]\n",
    "    if shape_dtype in [\"unpadded_shape\", \"dtype\"]:\n",
    "        unpadded_global_shapes[param_key][shape_dtype] = v\n",
    "    shape_dtype = unpadded_global_shapes[param_key]\n",
    "    if len(shape_dtype) == 2:\n",
    "        shape_dtype = jax.ShapeDtypeStruct(\n",
    "            shape=shape_dtype[\"unpadded_shape\"], dtype=shape_dtype[\"dtype\"]\n",
    "        )\n",
    "        unpadded_global_shapes.update({param_key: shape_dtype})\n",
    "unflat_unpadded_global_shapes = unflatten_dict(unpadded_global_shapes)\n",
    "\n",
    "opt_unpadded_global_shapes = {}\n",
    "first_count = {'count': ShapeDtypeStruct(shape = (), dtype = np.int32)}\n",
    "last_count = {'count': ShapeDtypeStruct(shape = (layer_num // sub_layer_num, ), dtype = np.int32)}\n",
    "\n",
    "transformer_shapedtype = {p: shapedtype for p, shapedtype in unpadded_global_shapes.items() if 'transformer' in p}\n",
    "untransformer_shapedtype = {p: shapedtype for p, shapedtype in unpadded_global_shapes.items() if 'transformer' not in p}\n",
    "\n",
    "transformer_shapedtype = unflatten_dict(transformer_shapedtype)\n",
    "untransformer_shapedtype = unflatten_dict(untransformer_shapedtype)\n",
    "\n",
    "untransformer_mvcount = {\n",
    "    'count': ShapeDtypeStruct(shape = (), dtype = np.int32),\n",
    "    'm': untransformer_shapedtype['mdl_vars'],\n",
    "    'v': untransformer_shapedtype['mdl_vars']\n",
    "          }\n",
    "transformer_mvcount = {\n",
    "    'count': ShapeDtypeStruct(shape = (), dtype = np.int32),\n",
    "    'm': transformer_shapedtype['mdl_vars'],\n",
    "    'v': transformer_shapedtype['mdl_vars']\n",
    "          }\n",
    "\n",
    "untransformer_values = (first_count, first_count, untransformer_mvcount, last_count)\n",
    "transformer_values = (first_count, first_count, transformer_mvcount, last_count)\n",
    "\n",
    "for i in range(4):\n",
    "    opt_unpadded_global_shapes[f'no_prefix_{i}'] = untransformer_values[i]\n",
    "    opt_unpadded_global_shapes[f'p#{layer_num // sub_layer_num}#i-1_{i}'] = transformer_values[i]\n",
    "    \n",
    "opt_unpadded_global_shapes = {'opt_states_0': opt_unpadded_global_shapes}\n",
    "\n",
    "global_shapes = {\n",
    "    \"mdl_vars\": unflat_unpadded_global_shapes[\"mdl_vars\"], \n",
    "    \"opt_states_0\": opt_unpadded_global_shapes[\"opt_states_0\"], \n",
    "    \"step\": ShapeDtypeStruct(shape = (), dtype = np.int32),\n",
    "}\n",
    "\n",
    "# 基于mdl_vars和opt_states的shapedtype加载模型\n",
    "with jax.default_device(jax.devices(\"cpu\")[0]):\n",
    "    pax_state = pax_mngr.restore(load_step, items={'state':global_shapes})\n",
    "flat_pax_state = {'.'.join(k): v for k, v in flatten_dict(pax_state).items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3371a518-6061-4b28-a5a0-ae98026ead82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mgate 是小梦的模型，其他模型需要去掉\n",
    "pax2max = f'''\n",
    "pax_prefix_lm.embedding_lookup.emb_var (152064, 1024)\n",
    "max_prefix_token_embedder.embedding (152064, 1024)\n",
    "\n",
    "pax_prefix_lm.final_ln.scale (1024,)\n",
    "max_prefix_decoder.decoder_norm.scale (1024,)\n",
    "\n",
    "pax_prefix_lm.softmax.logits_ffn.linear.w (1024, 152064)\n",
    "max_prefix_decoder.logits_dense.kernel (1024, 152064)\n",
    "\n",
    "pax_prefix_lm.transformer.repeat.sub.x_layers_0.ff_layer.mgate_layer.linear.w (1024, 44)\n",
    "max_prefix_decoder.layers.mlp_0.mgate.kernel (1024, 44)\n",
    "\n",
    "pax_prefix_lm.transformer.repeat.sub.x_layers_0.ff_layer.ffn_layer1.linear.w (1024, 12, 2816)\n",
    "max_prefix_decoder.layers.mlp_0.wi_1.kernel (1024, 12, 2816)\n",
    "\n",
    "pax_prefix_lm.transformer.repeat.sub.x_layers_0.ff_layer.ffn_layer1_gate.linear.w (1024, 12, 2816)\n",
    "max_prefix_decoder.layers.mlp_0.wi_0.kernel (1024, 12, 2816)\n",
    "\n",
    "pax_prefix_lm.transformer.repeat.sub.x_layers_0.ff_layer.ffn_layer2.linear.w (2816, 12, 1024)\n",
    "max_prefix_decoder.layers.mlp_0.wo.kernel (2816, 12, 1024)\n",
    "\n",
    "pax_prefix_lm.transformer.repeat.sub.x_layers_0.ff_layer.layer_norm.scale (1024, 12)\n",
    "max_prefix_decoder.layers.post_self_attention_layer_norm_0.scale (1024, 12)\n",
    "\n",
    "pax_prefix_lm.transformer.repeat.sub.x_layers_0.layer_norm.scale (1024, 12)\n",
    "max_prefix_decoder.layers.pre_self_attention_layer_norm_0.scale (1024, 12)\n",
    "\n",
    "pax_prefix_lm.transformer.repeat.sub.x_layers_0.self_attention.dyn_w_proj.dd (1024, 12, 1, 64)\n",
    "max_prefix_decoder.layers.self_attention_0.AttentionOp_0.dyn_w_proj.dd.kernel (1024, 12, 1, 64)\n",
    "\n",
    "pax_prefix_lm.transformer.repeat.sub.x_layers_0.self_attention.dyn_w_proj.dw1 (1024, 12, 1, 4, 64)\n",
    "max_prefix_decoder.layers.self_attention_0.AttentionOp_0.dyn_w_proj.dw1.kernel (1024, 12, 1, 4, 64)\n",
    "\n",
    "pax_prefix_lm.transformer.repeat.sub.x_layers_0.self_attention.dyn_w_proj.qkw (1, 12, 4, 64, 4, 16)\n",
    "max_prefix_decoder.layers.self_attention_0.AttentionOp_0.dyn_w_proj.qkw (1, 12, 4, 64, 4, 16)\n",
    "\n",
    "pax_prefix_lm.transformer.repeat.sub.x_layers_0.self_attention.k_norm.scale (128, 12)\n",
    "max_prefix_decoder.layers.self_attention_0.k_norm.scale (128, 12)\n",
    "\n",
    "pax_prefix_lm.transformer.repeat.sub.x_layers_0.self_attention.key.w (1024, 12, 16, 128)\n",
    "max_prefix_decoder.layers.self_attention_0.key.kernel (1024, 12, 16, 128)\n",
    "\n",
    "pax_prefix_lm.transformer.repeat.sub.x_layers_0.self_attention.post.w (16, 12, 128, 1024)\n",
    "max_prefix_decoder.layers.self_attention_0.out.kernel (16, 12, 128, 1024)\n",
    "\n",
    "pax_prefix_lm.transformer.repeat.sub.x_layers_0.self_attention.q_norm.scale (128, 12)\n",
    "max_prefix_decoder.layers.self_attention_0.q_norm.scale (128, 12)\n",
    "\n",
    "pax_prefix_lm.transformer.repeat.sub.x_layers_0.self_attention.query.w (1024, 12, 16, 128)\n",
    "max_prefix_decoder.layers.self_attention_0.query.kernel (1024, 12, 16, 128)\n",
    "\n",
    "pax_prefix_lm.transformer.repeat.sub.x_layers_0.self_attention.value.w (1024, 12, 16, 128)\n",
    "max_prefix_decoder.layers.self_attention_0.value.kernel (1024, 12, 16, 128)\n",
    "'''\n",
    "pax2max = pax2max.split('\\n')\n",
    "pax2max = [l.strip() for l in pax2max if l.strip()]\n",
    "\n",
    "## params\n",
    "def replace_prefix(key:str, replace_prefixs:dict, instrings:dict={}, outstrings:dict={}):\n",
    "    new_key = None\n",
    "    for prefix, replace_prefix in replace_prefixs.items():\n",
    "        if instrings and instrings[prefix] not in key:\n",
    "            continue\n",
    "        if outstrings and outstrings[prefix] in key:\n",
    "            continue\n",
    "        if prefix in key:\n",
    "            new_key = re.subn(f'{prefix}_', replace_prefix, key, count=1)[0]\n",
    "            break\n",
    "    return new_key\n",
    "    \n",
    "prefixs = {'pax_prefix': 'state.mdl_vars.params.', 'max_prefix': 'state.params.params.'}\n",
    "params_pax2max = [replace_prefix(key, prefixs) for key in pax2max]\n",
    "\n",
    "opt_mv_pax2maxs = []\n",
    "for mv in ['m', 'v']:\n",
    "    max_mv = 'mu' if mv == 'm' else 'nu'\n",
    "    prefixs = {'pax_prefix': f'state.opt_states_0.no_prefix_2.{mv}.params.', 'max_prefix': f'state.opt_state.{max_mv}.params.'}\n",
    "    outstrings = {'pax_prefix': 'transformer', 'max_prefix': 'layers'}\n",
    "    opt_mv_pax2max_0 = [replace_prefix(key, prefixs, outstrings=outstrings) for key in pax2max \n",
    "                     if replace_prefix(key, prefixs, outstrings=outstrings)]\n",
    "    \n",
    "    prefixs = {'pax_prefix': f'state.opt_states_0.p#12#i-1_2.{mv}.params.', 'max_prefix': f'state.opt_state.{max_mv}.params.'}\n",
    "    instrings = {'pax_prefix': 'transformer', 'max_prefix': 'layers'}\n",
    "    opt_mv_pax2max_1 = [replace_prefix(key, prefixs, instrings=instrings) for key in pax2max \n",
    "                     if replace_prefix(key, prefixs, instrings=instrings)]\n",
    "\n",
    "    opt_mv_pax2max = opt_mv_pax2max_0 + opt_mv_pax2max_1\n",
    "    opt_mv_pax2maxs.append(opt_mv_pax2max)\n",
    "\n",
    "state_pax2max = {'params': params_pax2max, 'm': opt_mv_pax2maxs[0], 'v': opt_mv_pax2maxs[1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed3b1136-27d1-42ef-9ee1-4e743b97fdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False state.mdl_vars.params.lm.embedding_lookup.emb_var (152064, 4096)\n",
      "False state.mdl_vars.params.lm.final_ln.scale (4096,)\n",
      "False state.mdl_vars.params.lm.softmax.logits_ffn.linear.w (4096, 152064)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_0.ff_layer.ffn_layer1.linear.w (4096, 12, 5632)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_0.ff_layer.ffn_layer1_gate.linear.w (4096, 12, 5632)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_0.ff_layer.ffn_layer2.linear.w (5632, 12, 4096)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_0.ff_layer.layer_norm.scale (4096, 12)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_0.ff_layer.mgate_layer.linear.w (4096, 12, 44)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_0.layer_norm.scale (4096, 12)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_0.self_attention.dyn_w_proj.dd (4096, 12, 1, 128)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_0.self_attention.dyn_w_proj.dw1 (4096, 12, 1, 4, 128)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_0.self_attention.dyn_w_proj.qkw (1, 12, 4, 128, 4, 32)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_0.self_attention.k_norm.scale (128, 12)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_0.self_attention.key.w (4096, 12, 32, 128)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_0.self_attention.post.w (32, 12, 128, 4096)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_0.self_attention.q_norm.scale (128, 12)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_0.self_attention.query.w (4096, 12, 32, 128)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_0.self_attention.value.w (4096, 12, 32, 128)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_1.ff_layer.ffn_layer1.linear.w (4096, 12, 5632)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_1.ff_layer.ffn_layer1_gate.linear.w (4096, 12, 5632)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_1.ff_layer.ffn_layer2.linear.w (5632, 12, 4096)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_1.ff_layer.layer_norm.scale (4096, 12)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_1.ff_layer.mgate_layer.linear.w (4096, 12, 44)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_1.layer_norm.scale (4096, 12)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_1.self_attention.dyn_w_proj.dd (4096, 12, 1, 128)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_1.self_attention.dyn_w_proj.dw1 (4096, 12, 1, 4, 128)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_1.self_attention.dyn_w_proj.qkw (1, 12, 4, 128, 4, 32)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_1.self_attention.k_norm.scale (128, 12)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_1.self_attention.key.w (4096, 12, 32, 128)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_1.self_attention.post.w (32, 12, 128, 4096)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_1.self_attention.q_norm.scale (128, 12)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_1.self_attention.query.w (4096, 12, 32, 128)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_1.self_attention.value.w (4096, 12, 32, 128)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_2.ff_layer.ffn_layer1.linear.w (4096, 12, 5632)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_2.ff_layer.ffn_layer1_gate.linear.w (4096, 12, 5632)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_2.ff_layer.ffn_layer2.linear.w (5632, 12, 4096)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_2.ff_layer.layer_norm.scale (4096, 12)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_2.ff_layer.mgate_layer.linear.w (4096, 12, 44)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_2.layer_norm.scale (4096, 12)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_2.self_attention.dyn_w_proj.dd (4096, 12, 1, 128)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_2.self_attention.dyn_w_proj.dw1 (4096, 12, 1, 4, 128)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_2.self_attention.dyn_w_proj.qkw (1, 12, 4, 128, 4, 32)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_2.self_attention.k_norm.scale (128, 12)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_2.self_attention.key.w (4096, 12, 32, 128)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_2.self_attention.post.w (32, 12, 128, 4096)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_2.self_attention.q_norm.scale (128, 12)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_2.self_attention.query.w (4096, 12, 32, 128)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_2.self_attention.value.w (4096, 12, 32, 128)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_3.ff_layer.ffn_layer1.linear.w (4096, 12, 5632)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_3.ff_layer.ffn_layer1_gate.linear.w (4096, 12, 5632)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_3.ff_layer.ffn_layer2.linear.w (5632, 12, 4096)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_3.ff_layer.layer_norm.scale (4096, 12)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_3.ff_layer.mgate_layer.linear.w (4096, 12, 44)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_3.layer_norm.scale (4096, 12)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_3.self_attention.dyn_w_proj.dd (4096, 12, 1, 128)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_3.self_attention.dyn_w_proj.dw1 (4096, 12, 1, 4, 128)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_3.self_attention.dyn_w_proj.qkw (1, 12, 4, 128, 4, 32)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_3.self_attention.k_norm.scale (128, 12)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_3.self_attention.key.w (4096, 12, 32, 128)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_3.self_attention.post.w (32, 12, 128, 4096)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_3.self_attention.q_norm.scale (128, 12)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_3.self_attention.query.w (4096, 12, 32, 128)\n",
      "True state.mdl_vars.params.lm.transformer.repeat.sub.x_layers_3.self_attention.value.w (4096, 12, 32, 128)\n",
      "filter key: state.opt_states_0.no_prefix_0.count =========\n",
      "filter key: state.opt_states_0.no_prefix_1.count =========\n",
      "filter key: state.opt_states_0.no_prefix_2.count =========\n",
      "False state.opt_states_0.no_prefix_2.m.params.lm.embedding_lookup.emb_var (152064, 4096)\n",
      "False state.opt_states_0.no_prefix_2.m.params.lm.final_ln.scale (4096,)\n",
      "False state.opt_states_0.no_prefix_2.m.params.lm.softmax.logits_ffn.linear.w (4096, 152064)\n",
      "False state.opt_states_0.no_prefix_2.v.params.lm.embedding_lookup.emb_var (152064, 4096)\n",
      "False state.opt_states_0.no_prefix_2.v.params.lm.final_ln.scale (4096,)\n",
      "False state.opt_states_0.no_prefix_2.v.params.lm.softmax.logits_ffn.linear.w (4096, 152064)\n",
      "filter key: state.opt_states_0.no_prefix_3.count =========\n",
      "filter key: state.opt_states_0.p#12#i-1_0.count =========\n",
      "filter key: state.opt_states_0.p#12#i-1_1.count =========\n",
      "filter key: state.opt_states_0.p#12#i-1_2.count =========\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_0.ff_layer.ffn_layer1.linear.w (4096, 12, 5632)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_0.ff_layer.ffn_layer1_gate.linear.w (4096, 12, 5632)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_0.ff_layer.ffn_layer2.linear.w (5632, 12, 4096)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_0.ff_layer.layer_norm.scale (4096, 12)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_0.ff_layer.mgate_layer.linear.w (4096, 12, 44)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_0.layer_norm.scale (4096, 12)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_0.self_attention.dyn_w_proj.dd (4096, 12, 1, 128)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_0.self_attention.dyn_w_proj.dw1 (4096, 12, 1, 4, 128)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_0.self_attention.dyn_w_proj.qkw (1, 12, 4, 128, 4, 32)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_0.self_attention.k_norm.scale (128, 12)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_0.self_attention.key.w (4096, 12, 32, 128)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_0.self_attention.post.w (32, 12, 128, 4096)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_0.self_attention.q_norm.scale (128, 12)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_0.self_attention.query.w (4096, 12, 32, 128)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_0.self_attention.value.w (4096, 12, 32, 128)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_1.ff_layer.ffn_layer1.linear.w (4096, 12, 5632)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_1.ff_layer.ffn_layer1_gate.linear.w (4096, 12, 5632)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_1.ff_layer.ffn_layer2.linear.w (5632, 12, 4096)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_1.ff_layer.layer_norm.scale (4096, 12)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_1.ff_layer.mgate_layer.linear.w (4096, 12, 44)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_1.layer_norm.scale (4096, 12)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_1.self_attention.dyn_w_proj.dd (4096, 12, 1, 128)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_1.self_attention.dyn_w_proj.dw1 (4096, 12, 1, 4, 128)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_1.self_attention.dyn_w_proj.qkw (1, 12, 4, 128, 4, 32)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_1.self_attention.k_norm.scale (128, 12)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_1.self_attention.key.w (4096, 12, 32, 128)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_1.self_attention.post.w (32, 12, 128, 4096)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_1.self_attention.q_norm.scale (128, 12)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_1.self_attention.query.w (4096, 12, 32, 128)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_1.self_attention.value.w (4096, 12, 32, 128)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_2.ff_layer.ffn_layer1.linear.w (4096, 12, 5632)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_2.ff_layer.ffn_layer1_gate.linear.w (4096, 12, 5632)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_2.ff_layer.ffn_layer2.linear.w (5632, 12, 4096)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_2.ff_layer.layer_norm.scale (4096, 12)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_2.ff_layer.mgate_layer.linear.w (4096, 12, 44)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_2.layer_norm.scale (4096, 12)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_2.self_attention.dyn_w_proj.dd (4096, 12, 1, 128)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_2.self_attention.dyn_w_proj.dw1 (4096, 12, 1, 4, 128)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_2.self_attention.dyn_w_proj.qkw (1, 12, 4, 128, 4, 32)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_2.self_attention.k_norm.scale (128, 12)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_2.self_attention.key.w (4096, 12, 32, 128)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_2.self_attention.post.w (32, 12, 128, 4096)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_2.self_attention.q_norm.scale (128, 12)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_2.self_attention.query.w (4096, 12, 32, 128)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_2.self_attention.value.w (4096, 12, 32, 128)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_3.ff_layer.ffn_layer1.linear.w (4096, 12, 5632)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_3.ff_layer.ffn_layer1_gate.linear.w (4096, 12, 5632)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_3.ff_layer.ffn_layer2.linear.w (5632, 12, 4096)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_3.ff_layer.layer_norm.scale (4096, 12)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_3.ff_layer.mgate_layer.linear.w (4096, 12, 44)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_3.layer_norm.scale (4096, 12)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_3.self_attention.dyn_w_proj.dd (4096, 12, 1, 128)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_3.self_attention.dyn_w_proj.dw1 (4096, 12, 1, 4, 128)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_3.self_attention.dyn_w_proj.qkw (1, 12, 4, 128, 4, 32)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_3.self_attention.k_norm.scale (128, 12)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_3.self_attention.key.w (4096, 12, 32, 128)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_3.self_attention.post.w (32, 12, 128, 4096)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_3.self_attention.q_norm.scale (128, 12)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_3.self_attention.query.w (4096, 12, 32, 128)\n",
      "True state.opt_states_0.p#12#i-1_2.m.params.lm.transformer.repeat.sub.x_layers_3.self_attention.value.w (4096, 12, 32, 128)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_0.ff_layer.ffn_layer1.linear.w (4096, 12, 5632)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_0.ff_layer.ffn_layer1_gate.linear.w (4096, 12, 5632)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_0.ff_layer.ffn_layer2.linear.w (5632, 12, 4096)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_0.ff_layer.layer_norm.scale (4096, 12)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_0.ff_layer.mgate_layer.linear.w (4096, 12, 44)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_0.layer_norm.scale (4096, 12)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_0.self_attention.dyn_w_proj.dd (4096, 12, 1, 128)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_0.self_attention.dyn_w_proj.dw1 (4096, 12, 1, 4, 128)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_0.self_attention.dyn_w_proj.qkw (1, 12, 4, 128, 4, 32)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_0.self_attention.k_norm.scale (128, 12)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_0.self_attention.key.w (4096, 12, 32, 128)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_0.self_attention.post.w (32, 12, 128, 4096)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_0.self_attention.q_norm.scale (128, 12)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_0.self_attention.query.w (4096, 12, 32, 128)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_0.self_attention.value.w (4096, 12, 32, 128)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_1.ff_layer.ffn_layer1.linear.w (4096, 12, 5632)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_1.ff_layer.ffn_layer1_gate.linear.w (4096, 12, 5632)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_1.ff_layer.ffn_layer2.linear.w (5632, 12, 4096)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_1.ff_layer.layer_norm.scale (4096, 12)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_1.ff_layer.mgate_layer.linear.w (4096, 12, 44)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_1.layer_norm.scale (4096, 12)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_1.self_attention.dyn_w_proj.dd (4096, 12, 1, 128)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_1.self_attention.dyn_w_proj.dw1 (4096, 12, 1, 4, 128)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_1.self_attention.dyn_w_proj.qkw (1, 12, 4, 128, 4, 32)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_1.self_attention.k_norm.scale (128, 12)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_1.self_attention.key.w (4096, 12, 32, 128)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_1.self_attention.post.w (32, 12, 128, 4096)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_1.self_attention.q_norm.scale (128, 12)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_1.self_attention.query.w (4096, 12, 32, 128)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_1.self_attention.value.w (4096, 12, 32, 128)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_2.ff_layer.ffn_layer1.linear.w (4096, 12, 5632)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_2.ff_layer.ffn_layer1_gate.linear.w (4096, 12, 5632)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_2.ff_layer.ffn_layer2.linear.w (5632, 12, 4096)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_2.ff_layer.layer_norm.scale (4096, 12)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_2.ff_layer.mgate_layer.linear.w (4096, 12, 44)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_2.layer_norm.scale (4096, 12)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_2.self_attention.dyn_w_proj.dd (4096, 12, 1, 128)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_2.self_attention.dyn_w_proj.dw1 (4096, 12, 1, 4, 128)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_2.self_attention.dyn_w_proj.qkw (1, 12, 4, 128, 4, 32)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_2.self_attention.k_norm.scale (128, 12)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_2.self_attention.key.w (4096, 12, 32, 128)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_2.self_attention.post.w (32, 12, 128, 4096)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_2.self_attention.q_norm.scale (128, 12)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_2.self_attention.query.w (4096, 12, 32, 128)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_2.self_attention.value.w (4096, 12, 32, 128)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_3.ff_layer.ffn_layer1.linear.w (4096, 12, 5632)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_3.ff_layer.ffn_layer1_gate.linear.w (4096, 12, 5632)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_3.ff_layer.ffn_layer2.linear.w (5632, 12, 4096)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_3.ff_layer.layer_norm.scale (4096, 12)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_3.ff_layer.mgate_layer.linear.w (4096, 12, 44)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_3.layer_norm.scale (4096, 12)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_3.self_attention.dyn_w_proj.dd (4096, 12, 1, 128)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_3.self_attention.dyn_w_proj.dw1 (4096, 12, 1, 4, 128)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_3.self_attention.dyn_w_proj.qkw (1, 12, 4, 128, 4, 32)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_3.self_attention.k_norm.scale (128, 12)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_3.self_attention.key.w (4096, 12, 32, 128)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_3.self_attention.post.w (32, 12, 128, 4096)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_3.self_attention.q_norm.scale (128, 12)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_3.self_attention.query.w (4096, 12, 32, 128)\n",
      "True state.opt_states_0.p#12#i-1_2.v.params.lm.transformer.repeat.sub.x_layers_3.self_attention.value.w (4096, 12, 32, 128)\n",
      "filter key: state.opt_states_0.p#12#i-1_3.count =========\n",
      "filter key: state.step =========\n"
     ]
    }
   ],
   "source": [
    "# 对模型参数进行trannspose\n",
    "pax_combine_w = {}\n",
    "for k, v in flat_pax_state.items():\n",
    "    if 'count' in k or 'step' in k:\n",
    "        print(f'filter key: {k} =========')\n",
    "        continue\n",
    "    ws = v\n",
    "    transpose = v.shape[0] == layer_num // sub_layer_num\n",
    "    if transpose:\n",
    "        ws = ws.transpose(1, 0, *range(2, v.ndim))\n",
    "    if 'post.w' in k:\n",
    "        ws = ws.transpose(2, 1, 3, 0)\n",
    "    print(transpose, k, ws.shape)\n",
    "    pax_combine_w[k] = ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2863c2c9-76e2-409e-a572-ca35f4c453fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 制作其他层的mapkey\n",
    "pax2max_keys = {}\n",
    "for k, pax2max in  state_pax2max.items():\n",
    "    for i in range(0, len(pax2max) - 1, 2):\n",
    "        pkey, pshape = pax2max[i].split('(')\n",
    "        pkey = pkey.strip()\n",
    "        pshape = '(' + pshape\n",
    "        mkey, mshape = pax2max[i + 1].split('(')\n",
    "        mshape = '(' + mshape\n",
    "        mkey = mkey.strip()\n",
    "        assert eval(pshape) == eval(mshape)\n",
    "        pax2max_keys[pkey] = mkey\n",
    "        if '.repeat.sub.x_layers_0' in pkey:\n",
    "            for j in range(1, sub_layer_num):\n",
    "                newpkey = re.subn('x_layers_0', f'x_layers_{j}', pkey, count=1)[0]\n",
    "                newmkey = re.subn('_0', f'_{j}', mkey, count=1)[0]\n",
    "                pax2max_keys[newpkey] = newmkey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94185a0b-42ce-44ec-9cb9-19e638ff0601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 制作其他层的mapkey\n",
    "pax2max_keys = {}\n",
    "for k, pax2max in  state_pax2max.items():\n",
    "    for i in range(0, len(pax2max) - 1, 2):\n",
    "        pkey, pshape = pax2max[i].split('(')\n",
    "        pkey = pkey.strip()\n",
    "        pshape = '(' + pshape\n",
    "        mkey, mshape = pax2max[i + 1].split('(')\n",
    "        mshape = '(' + mshape\n",
    "        mkey = mkey.strip()\n",
    "        assert eval(pshape) == eval(mshape)\n",
    "        pax2max_keys[pkey] = mkey\n",
    "        if '.repeat.sub.x_layers_0' in pkey:\n",
    "            for i in range(1, sub_layer_num):\n",
    "                newpkey = re.subn('x_layers_0', f'x_layers_{i}', pkey, count=1)[0]\n",
    "                newmkey = re.subn('_0', f'_{i}', mkey, count=1)[0]\n",
    "                pax2max_keys[newpkey] = newmkey\n",
    "\n",
    "# 基于key map将模型参数进行转换\n",
    "convert_to_max_w = {}\n",
    "for k, v in pax_combine_w.items():\n",
    "    max_key = pax2max_keys[k]\n",
    "    max_key = tuple(max_key.split('.'))\n",
    "    convert_to_max_w[max_key] = v\n",
    "unflat_convert_to_max_w = unflatten_dict(convert_to_max_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d06bb98-8e57-4c78-bee9-053e639fc257",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dir = \"gs://llm_base_models/maxtext_align_pax_dc/maxtext_align2/checkpoints\"\n",
    "save_dir = \"gs://llm_base_models_us-east5/v5p_256/7B/PileDCSlimLlama7B32Kx4x256x1v5p_0705/checkpoints/\"\n",
    "step_format_fixed_length = None\n",
    "options = orbax.checkpoint.CheckpointManagerOptions()\n",
    "item = {\n",
    "    \"state\": orbax.checkpoint.Checkpointer(orbax.checkpoint.PyTreeCheckpointHandler())\n",
    "}\n",
    "max_mngr = orbax.checkpoint.CheckpointManager(save_dir, item, options)\n",
    "\n",
    "save_step = load_step # 实验随意，转换的是需要设置为load_step\n",
    "\n",
    "unflat_convert_to_max_w['state']['step'] = np.array(save_step, dtype=np.uint32)\n",
    "unflat_convert_to_max_w['state']['opt_state']['count'] = np.array(save_step, dtype=np.uint32)\n",
    "max_mngr.save(save_step, unflat_convert_to_max_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1752e7-449f-426c-9856-19043f37cec2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
