{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9772c70-ee9a-496d-b5c5-0baa42cac0d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-05 11:56:44.849293: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-05 11:56:45.140395: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-05 11:56:45.142475: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-05 11:56:47.307694: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old structure file keys: dict_keys(['params'])\n",
      "New structure file keys: dict_keys(['params'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733399838.006031   20636 gcs_resource.cc:109] Using default AdmissionQueue with limit 32\n",
      "I0000 00:00:1733399838.019827   21457 google_auth_provider.cc:180] Running on GCE, using service account 887571727717-compute@developer.gserviceaccount.com\n"
     ]
    }
   ],
   "source": [
    "# !pip install tensorflow==2.16.1\n",
    "# pip install numpy==1.26.4\n",
    "# 运行2遍\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import asyncio\n",
    "import argparse\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import subprocess\n",
    "\n",
    "os.environ[\"JAX_PLATFORMS\"] = \"cpu\"\n",
    "from etils import epath\n",
    "import json\n",
    "import base64\n",
    "\n",
    "import numpy as np\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import orbax\n",
    "import orbax.checkpoint as ocp\n",
    "from etils import epath\n",
    "from jax.sharding import PartitionSpec as PS\n",
    "from flax.traverse_util import flatten_dict, unflatten_dict\n",
    "\n",
    "\n",
    "METADATA_FILE = '_METADATA'\n",
    "_CHECKPOINT_FILE = 'checkpoint'\n",
    "\n",
    "\n",
    "read_dir = 'gs://llm_base_models_europe-west4/v5p_256/7B/PileDCSlimLlama7B32Kx4x256x1v5p_0713/checkpoints/440000/state'\n",
    "save_dir = 'gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/'\n",
    "# read_dir = 'gs://llm_base_models_europe-west4/v5p_256/7B/xm_M8x7B_WithMgateNoshareCopymlp_1129/checkpoints/1400/state'\n",
    "\n",
    "read_dir = epath.Path(read_dir) \n",
    "# save_dir = epath.Path(save_dir)\n",
    "\n",
    "metadata_path = read_dir / METADATA_FILE\n",
    "back_metadata_path = read_dir / f'{METADATA_FILE}.back'\n",
    "try:\n",
    "    metadata_path.rename(back_metadata_path)\n",
    "except:\n",
    "    pass\n",
    "metadata_path.unlink(missing_ok=True) # delete\n",
    "structure_path = read_dir / _CHECKPOINT_FILE\n",
    "msgpack = ocp.aggregate_handlers.MsgpackHandler(0)\n",
    "structure = msgpack.deserialize(structure_path)\n",
    "# backup original checkpoint fil\n",
    "back_structure_path = read_dir / 'checkpoint_back'\n",
    "back_structure = structure.copy()\n",
    "if not back_structure_path.exists():\n",
    "    asyncio.run(msgpack.serialize(back_structure_path, item=back_structure))\n",
    "print(f'Old structure file keys: {structure.keys()}')\n",
    "remove_keys = ['opt_state', 'step'] # select the weight name you don't want to load, all weight name: opt_state, step, params\n",
    "_ = [structure.pop(key) for key in remove_keys if key in structure]\n",
    "print(f'New structure file keys: {structure.keys()}')\n",
    "asyncio.run(msgpack.serialize(structure_path, item=structure))  # rewrite struct file\n",
    "\n",
    "# load model based struct, note: axes must same as training\n",
    "mesh_axes = ['data', 'stage', 'fsdp', 'fsdp_transpose', 'sequence', 'tensor', 'autoregressive']\n",
    "devices = np.asarray(jax.devices()).reshape([1] * len(mesh_axes))\n",
    "mesh = jax.sharding.Mesh(devices, mesh_axes)\n",
    "sharding = jax.sharding.NamedSharding(mesh, PS()) # Sharding is None because we use cpu to load weights\n",
    "weight_dtype = jnp.bfloat16 # set restore weights dtype\n",
    "restore_args = {}\n",
    "for k, v in flatten_dict(structure).items():\n",
    "    restore_args[k] =  ocp.ArrayRestoreArgs(restore_type=jax.Array, dtype=weight_dtype, sharding=sharding)\n",
    "restore_args = unflatten_dict(restore_args)\n",
    "ckptr = ocp.Checkpointer(ocp.PyTreeCheckpointHandler())\n",
    "w = ckptr.restore(read_dir, args=ocp.args.PyTreeRestore(restore_args=restore_args))\n",
    "structure_path = read_dir / _CHECKPOINT_FILE\n",
    "# rewrite struct file, otherwise occur error when continue training\n",
    "asyncio.run(msgpack.serialize(structure_path, item=back_structure))\n",
    "while 'params' in w:\n",
    "    w = w['params']\n",
    "xm3p5_w = {'.'.join(k): np.array(v) for k, v in flatten_dict(w).items()}\n",
    "\n",
    "try:\n",
    "    back_metadata_path.rename(metadata_path)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d01706cf-0274-48ee-af3f-5706cef728c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 基于dense模型保存和moe相同名字的参数\n",
    "def convert_to_jnp(params, remove_keys=[]):\n",
    "    convert_params = {}\n",
    "    for k, v in params.items():\n",
    "        r = 0\n",
    "        for remove_key in remove_keys:\n",
    "            if remove_key in k: \n",
    "                r = 1\n",
    "                break\n",
    "        if r: continue\n",
    "        k = tuple(k.split('.'))\n",
    "        convert_params[k] = v\n",
    "        # convert_params[k] = jnp.array(v).astype(jnp.bfloat16)\n",
    "    for k, v in convert_params.items():\n",
    "        print(k, v.shape, v.dtype)\n",
    "    return convert_params\n",
    "\n",
    "\n",
    "def save_params(step, save_dir, params):\n",
    "    item = {\n",
    "            'state': orbax.checkpoint.AsyncCheckpointer(orbax.checkpoint.PyTreeCheckpointHandler(use_ocdbt=False)),\n",
    "                    }\n",
    "    unflatten_params = unflatten_dict(params)\n",
    "    for k, v in params.items():\n",
    "        print(k, v.shape, v.dtype)\n",
    "    mngr = orbax.checkpoint.CheckpointManager(save_dir, item)\n",
    "    if 'params' not in unflatten_params: unflatten_params = {'params': unflatten_params}\n",
    "    mngr.save(step, items={'state': {'params': unflatten_params}})\n",
    "\n",
    "params_save_step = 0\n",
    "# convert_params = convert_to_jnp(xm3p5_w, remove_keys=['mlp_'])\n",
    "# save_params(params_save_step, save_dir, convert_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59871ef5-b54c-4d89-bf0d-e77d8033e1c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "router_gate: decoder.layers.unshared_mlp_0.router_gate.kernel init_v: (4096, 12, 8)\n",
      "router_gate: decoder.layers.unshared_mlp_1.router_gate.kernel init_v: (4096, 12, 8)\n",
      "router_gate: decoder.layers.unshared_mlp_2.router_gate.kernel init_v: (4096, 12, 8)\n",
      "router_gate: decoder.layers.unshared_mlp_3.router_gate.kernel init_v: (4096, 12, 8)\n",
      "('decoder', 'layers', 'unshared_mlp_0', 'mgate') (8, 12, 4096, 44) -2.78125 -2.78125\n",
      "('decoder', 'layers', 'unshared_mlp_0', 'router_gate', 'kernel') (4096, 12, 8) 0.0144043 -0.034668\n",
      "('decoder', 'layers', 'unshared_mlp_0', 'wi_0') (8, 12, 4096, 5632) 5312 4192\n",
      "('decoder', 'layers', 'unshared_mlp_0', 'wi_1') (8, 12, 4096, 5632) 968 1088\n",
      "('decoder', 'layers', 'unshared_mlp_0', 'wo') (8, 12, 5632, 4096) -184 147\n",
      "('decoder', 'layers', 'unshared_mlp_1', 'mgate') (8, 12, 4096, 44) 50 50\n",
      "('decoder', 'layers', 'unshared_mlp_1', 'router_gate', 'kernel') (4096, 12, 8) 0.0144043 -0.034668\n",
      "('decoder', 'layers', 'unshared_mlp_1', 'wi_0') (8, 12, 4096, 5632) 5984 6272\n",
      "('decoder', 'layers', 'unshared_mlp_1', 'wi_1') (8, 12, 4096, 5632) -244 -468\n",
      "('decoder', 'layers', 'unshared_mlp_1', 'wo') (8, 12, 5632, 4096) 644 672\n",
      "('decoder', 'layers', 'unshared_mlp_2', 'mgate') (8, 12, 4096, 44) 29.125 29.125\n",
      "('decoder', 'layers', 'unshared_mlp_2', 'router_gate', 'kernel') (4096, 12, 8) 0.0144043 -0.034668\n",
      "('decoder', 'layers', 'unshared_mlp_2', 'wi_0') (8, 12, 4096, 5632) 3760 3824\n",
      "('decoder', 'layers', 'unshared_mlp_2', 'wi_1') (8, 12, 4096, 5632) -250 -372\n",
      "('decoder', 'layers', 'unshared_mlp_2', 'wo') (8, 12, 5632, 4096) 660 -35\n",
      "('decoder', 'layers', 'unshared_mlp_3', 'mgate') (8, 12, 4096, 44) 5.71875 5.71875\n",
      "('decoder', 'layers', 'unshared_mlp_3', 'router_gate', 'kernel') (4096, 12, 8) 0.0144043 -0.034668\n",
      "('decoder', 'layers', 'unshared_mlp_3', 'wi_0') (8, 12, 4096, 5632) 5824 5696\n",
      "('decoder', 'layers', 'unshared_mlp_3', 'wi_1') (8, 12, 4096, 5632) 448 -123\n",
      "('decoder', 'layers', 'unshared_mlp_3', 'wo') (8, 12, 5632, 4096) 46 105\n"
     ]
    }
   ],
   "source": [
    "def nd_dense_init(scale, mode, distribution):\n",
    "  \"\"\"Initializer with in_axis, out_axis set at call time.\"\"\"\n",
    "\n",
    "  def init_fn(key, shape, dtype, in_axis, out_axis):\n",
    "    fn = jax.nn.initializers.variance_scaling(scale, mode, distribution, in_axis, out_axis)\n",
    "    return fn(key, shape, dtype)\n",
    "\n",
    "  return init_fn\n",
    "\n",
    "init_func = nd_dense_init(1.0, \"fan_in\", \"truncated_normal\")\n",
    "\n",
    "\n",
    "## moe部分的参数保存，保存后在bucket后台人工进行转移\n",
    "start_time = time.time()\n",
    "unshared_experts = 8\n",
    "\n",
    "scale = 1\n",
    "mlp_dim = 5632 // scale\n",
    "model_dim = 4096 // scale\n",
    "copy_dim = mlp_dim // unshared_experts\n",
    "\n",
    "# fp16_dtype = np.dtype('float16')\n",
    "# 4个子层\n",
    "moe_params = {}\n",
    "example_params = {}\n",
    "for k, v in xm3p5_w.items():\n",
    "    v = jnp.array(v).astype(jnp.bfloat16)\n",
    "    ev = jnp.array([100]).astype(jnp.bfloat16)\n",
    "    if 'decoder.layers.mlp_' in k:\n",
    "        mlp_inx = k.find('mlp_')\n",
    "        l = k[mlp_inx+4: mlp_inx+5]\n",
    "        unshared_mlp = k.replace('decoder.layers.mlp_', 'decoder.layers.unshared_mlp_')\n",
    "        unshared_mlp = unshared_mlp.replace('.kernel', '')\n",
    "        if 'mgate' in unshared_mlp:\n",
    "            init_w = v.transpose(1, 0, 2)[None].repeat(unshared_experts, 0)\n",
    "        else:\n",
    "            v = v.transpose(1, 0, 2)\n",
    "            # unshared: unshared_experts * 12 * model_dim * mlp_dim,  mlp: model_dim * 12 * mlp_dim\n",
    "            unshared_mlp_w = []\n",
    "            if '.wo.' in k:\n",
    "                copy_w = v.reshape(12, unshared_experts, 1, copy_dim, model_dim).repeat(unshared_experts, 2).reshape(\n",
    "                    12, unshared_experts, -1, model_dim).transpose(1, 0, 2, 3)\n",
    "            else:\n",
    "                copy_w = v.reshape(12, model_dim, unshared_experts, 1, copy_dim).repeat(unshared_experts, 3).reshape(\n",
    "                    12, model_dim, unshared_experts, -1).transpose(2, 0, 1, 3)\n",
    "            v = v[None] # extend dim\n",
    "            init_w = (copy_w + v) / 2\n",
    "            \n",
    "        moe_params[unshared_mlp] = init_w\n",
    "        example_params[unshared_mlp] = ev\n",
    "        if 'mgate' in unshared_mlp:\n",
    "            router_gate = unshared_mlp.replace('mgate', 'router_gate.kernel')\n",
    "            # init_v = v[..., :unshared_experts]\n",
    "            # 为什么用这个初始化的时候，模型被load进cpu。取v的值的时候，被load进tpu，啥原因？\n",
    "            init_v = init_func(key=jax.random.PRNGKey(9876), shape=v[...,:unshared_experts].shape, dtype=jnp.bfloat16, in_axis=0, out_axis=2)\n",
    "            print(f'router_gate: {router_gate} init_v: {init_v.shape}')\n",
    "            moe_params[router_gate] = jnp.array(np.array(init_v))\n",
    "            example_params[router_gate] = ev\n",
    "    else:\n",
    "        example_params[k] = ev\n",
    "        \n",
    "            \n",
    "moe_params = {tuple(k.split('.')): v for k, v in moe_params.items()}\n",
    "example_params = {tuple(k.split('.')): v for k,v in example_params.items()}\n",
    "\n",
    "for k, v in moe_params.items():\n",
    "    print(k, v.shape, v[0].sum(), v[1].sum())\n",
    "\n",
    "moe_save_step = params_save_step + 1\n",
    "example_step = params_save_step + 2\n",
    "\n",
    "save_params(moe_save_step, save_dir, moe_params)\n",
    "save_params(example_step, save_dir, example_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "032a768e-8455-4c6b-8c4a-fc008ae62609",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/2/state/_METADATA [Content-Type=application/octet-stream]...\n",
      "/ [1 files][ 27.8 KiB/ 27.8 KiB]                                                \n",
      "Operation completed over 1 objects/27.8 KiB.                                     \n",
      "Copying gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/2/state/checkpoint...\n",
      "/ [1 files][  6.2 KiB/  6.2 KiB]                                                \n",
      "Operation completed over 1 objects/6.2 KiB.                                      \n",
      "Copying gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/1/state/params.params.decoder.layers.unshared_mlp_0.mgate/.zarray [Content-Type=application/octet-stream]...\n",
      "Copying gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/1/state/params.params.decoder.layers.unshared_mlp_0.mgate/0.0.0.0 [Content-Type=application/octet-stream]...\n",
      "Copying gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/1/state/params.params.decoder.layers.unshared_mlp_0.router_gate.kernel/.zarray [Content-Type=application/octet-stream]...\n",
      "Copying gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/1/state/params.params.decoder.layers.unshared_mlp_0.router_gate.kernel/0.0.0 [Content-Type=application/octet-stream]...\n",
      "Copying gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/1/state/params.params.decoder.layers.unshared_mlp_0.wi_0/.zarray [Content-Type=application/octet-stream]...\n",
      "Copying gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/1/state/params.params.decoder.layers.unshared_mlp_0.wi_0/0.0.0.0 [Content-Type=application/octet-stream]...\n",
      "Copying gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/1/state/params.params.decoder.layers.unshared_mlp_0.wi_1/.zarray [Content-Type=application/octet-stream]...\n",
      "Copying gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/1/state/params.params.decoder.layers.unshared_mlp_0.wi_1/0.0.0.0 [Content-Type=application/octet-stream]...\n",
      "Copying gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/1/state/params.params.decoder.layers.unshared_mlp_0.wo/.zarray [Content-Type=application/octet-stream]...\n",
      "Copying gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/1/state/params.params.decoder.layers.unshared_mlp_1.mgate/.zarray [Content-Type=application/octet-stream]...\n",
      "Copying gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/1/state/params.params.decoder.layers.unshared_mlp_0.wo/0.0.0.0 [Content-Type=application/octet-stream]...\n",
      "Copying gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/1/state/params.params.decoder.layers.unshared_mlp_1.router_gate.kernel/.zarray [Content-Type=application/octet-stream]...\n",
      "Copying gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/1/state/params.params.decoder.layers.unshared_mlp_1.mgate/0.0.0.0 [Content-Type=application/octet-stream]...\n",
      "Copying gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/1/state/params.params.decoder.layers.unshared_mlp_1.router_gate.kernel/0.0.0 [Content-Type=application/octet-stream]...\n",
      "Copying gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/1/state/params.params.decoder.layers.unshared_mlp_1.wi_0/.zarray [Content-Type=application/octet-stream]...\n",
      "Copying gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/1/state/params.params.decoder.layers.unshared_mlp_1.wi_0/0.0.0.0 [Content-Type=application/octet-stream]...\n",
      "Copying gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/1/state/params.params.decoder.layers.unshared_mlp_1.wi_1/.zarray [Content-Type=application/octet-stream]...\n",
      "Copying gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/1/state/params.params.decoder.layers.unshared_mlp_1.wi_1/0.0.0.0 [Content-Type=application/octet-stream]...\n",
      "Copying gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/1/state/params.params.decoder.layers.unshared_mlp_1.wo/.zarray [Content-Type=application/octet-stream]...\n",
      "Copying gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/1/state/params.params.decoder.layers.unshared_mlp_1.wo/0.0.0.0 [Content-Type=application/octet-stream]...\n",
      "Copying gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/1/state/params.params.decoder.layers.unshared_mlp_2.mgate/.zarray [Content-Type=application/octet-stream]...\n",
      "Copying gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/1/state/params.params.decoder.layers.unshared_mlp_2.router_gate.kernel/.zarray [Content-Type=application/octet-stream]...\n",
      "Copying gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/1/state/params.params.decoder.layers.unshared_mlp_2.mgate/0.0.0.0 [Content-Type=application/octet-stream]...\n",
      "Copying gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/1/state/params.params.decoder.layers.unshared_mlp_2.router_gate.kernel/0.0.0 [Content-Type=application/octet-stream]...\n",
      "Copying gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/1/state/params.params.decoder.layers.unshared_mlp_2.wi_0/.zarray [Content-Type=application/octet-stream]...\n",
      "Copying gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/1/state/params.params.decoder.layers.unshared_mlp_2.wi_1/.zarray [Content-Type=application/octet-stream]...\n",
      "Copying gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/1/state/params.params.decoder.layers.unshared_mlp_2.wi_0/0.0.0.0 [Content-Type=application/octet-stream]...\n",
      "Copying gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/1/state/params.params.decoder.layers.unshared_mlp_2.wi_1/0.0.0.0 [Content-Type=application/octet-stream]...\n",
      "Copying gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/1/state/params.params.decoder.layers.unshared_mlp_2.wo/.zarray [Content-Type=application/octet-stream]...\n",
      "Copying gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/1/state/params.params.decoder.layers.unshared_mlp_2.wo/0.0.0.0 [Content-Type=application/octet-stream]...\n",
      "Copying gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/1/state/params.params.decoder.layers.unshared_mlp_3.mgate/.zarray [Content-Type=application/octet-stream]...\n",
      "Copying gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/1/state/params.params.decoder.layers.unshared_mlp_3.mgate/0.0.0.0 [Content-Type=application/octet-stream]...\n",
      "Copying gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/1/state/params.params.decoder.layers.unshared_mlp_3.router_gate.kernel/.zarray [Content-Type=application/octet-stream]...\n",
      "Copying gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/1/state/params.params.decoder.layers.unshared_mlp_3.wi_0/.zarray [Content-Type=application/octet-stream]...\n",
      "Copying gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/1/state/params.params.decoder.layers.unshared_mlp_3.router_gate.kernel/0.0.0 [Content-Type=application/octet-stream]...\n",
      "Copying gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/1/state/params.params.decoder.layers.unshared_mlp_3.wi_1/.zarray [Content-Type=application/octet-stream]...\n",
      "Copying gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/1/state/params.params.decoder.layers.unshared_mlp_3.wi_0/0.0.0.0 [Content-Type=application/octet-stream]...\n",
      "Copying gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/1/state/params.params.decoder.layers.unshared_mlp_3.wi_1/0.0.0.0 [Content-Type=application/octet-stream]...\n",
      "Copying gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/1/state/params.params.decoder.layers.unshared_mlp_3.wo/0.0.0.0 [Content-Type=application/octet-stream]...\n",
      "Copying gs://llm_base_models_europe-west4/v5p_256/7B/xm_E8x7B_OnlyUnshareWithMgate_selfinit_1205/checkpoints/1/state/params.params.decoder.layers.unshared_mlp_3.wo/.zarray [Content-Type=application/octet-stream]...\n",
      "/ [40/60 files][ 38.4 GiB/ 38.4 GiB]  99% Done                                  \r"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "source_dir = str(save_dir).rstrip('/')\n",
    "target_dir = str(save_dir).rstrip('/')\n",
    "\n",
    "command = f'gsutil cp {source_dir}/{example_step}/state/_METADATA {target_dir}/{params_save_step}/state/ '\n",
    "r = subprocess.run(command, stdout=subprocess.PIPE, shell=True)\n",
    "\n",
    "command = f'gsutil cp {source_dir}/{example_step}/state/checkpoint {target_dir}/{params_save_step}/state/ '\n",
    "r = subprocess.run(command, stdout=subprocess.PIPE, shell=True)\n",
    "\n",
    "command = f'gsutil -m cp -r {source_dir}/{moe_save_step}/state/params.params* {target_dir}/{params_save_step}/state/ '\n",
    "r = subprocess.run(command, stdout=subprocess.PIPE, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "195a8b36-d67c-445e-b9c6-e77763126fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "core_nums: 16\n",
      "remove key: opt_state.mu.params.token_embedder.embedding\n",
      "remove key: opt_state.mu.params.decoder.decoder_norm.scale\n",
      "remove key: opt_state.mu.params.decoder.layers.unshared_mlp_0.wi_0\n",
      "remove key: opt_state.mu.params.decoder.layers.unshared_mlp_0.wi_1\n",
      "remove key: opt_state.mu.params.decoder.layers.unshared_mlp_0.wo\n",
      "remove key: opt_state.mu.params.decoder.layers.unshared_mlp_0.mgate\n",
      "remove key: opt_state.mu.params.decoder.layers.unshared_mlp_0.router_gate.kernel\n",
      "remove key: opt_state.mu.params.decoder.layers.unshared_mlp_2.wi_0\n",
      "remove key: opt_state.mu.params.decoder.layers.unshared_mlp_2.wi_1\n",
      "remove key: opt_state.mu.params.decoder.layers.unshared_mlp_2.wo\n",
      "remove key: opt_state.mu.params.decoder.layers.unshared_mlp_2.mgate\n",
      "remove key: opt_state.mu.params.decoder.layers.unshared_mlp_2.router_gate.kernel\n",
      "remove key: opt_state.mu.params.decoder.layers.mlp_0.wi_0.kernel\n",
      "remove key: opt_state.mu.params.decoder.layers.mlp_0.wi_1.kernel\n",
      "remove key: opt_state.mu.params.decoder.layers.mlp_0.wo.kernel\n",
      "remove key: opt_state.mu.params.decoder.layers.mlp_0.mgate.kernel\n",
      "remove key: opt_state.mu.params.decoder.layers.mlp_1.wi_0.kernel\n",
      "remove key: opt_state.mu.params.decoder.layers.mlp_1.wi_1.kernel\n",
      "remove key: opt_state.mu.params.decoder.layers.mlp_1.wo.kernel\n",
      "remove key: opt_state.mu.params.decoder.layers.mlp_1.mgate.kernel\n",
      "remove key: opt_state.mu.params.decoder.layers.mlp_2.wi_0.kernel\n",
      "remove key: opt_state.mu.params.decoder.layers.mlp_2.wi_1.kernel\n",
      "remove key: opt_state.mu.params.decoder.layers.mlp_2.wo.kernel\n",
      "remove key: opt_state.mu.params.decoder.layers.mlp_2.mgate.kernel\n",
      "remove key: opt_state.mu.params.decoder.layers.mlp_3.wi_0.kernel\n",
      "remove key: opt_state.mu.params.decoder.layers.mlp_3.wi_1.kernel\n",
      "remove key: opt_state.mu.params.decoder.layers.mlp_3.wo.kernel\n",
      "remove key: opt_state.mu.params.decoder.layers.mlp_3.mgate.kernel\n",
      "remove key: opt_state.mu.params.decoder.layers.post_self_attention_layer_norm_0.scale\n",
      "remove key: opt_state.mu.params.decoder.layers.post_self_attention_layer_norm_1.scale\n",
      "remove key: opt_state.mu.params.decoder.layers.post_self_attention_layer_norm_2.scale\n",
      "remove key: opt_state.mu.params.decoder.layers.post_self_attention_layer_norm_3.scale\n",
      "remove key: opt_state.mu.params.decoder.layers.pre_self_attention_layer_norm_0.scale\n",
      "remove key: opt_state.mu.params.decoder.layers.pre_self_attention_layer_norm_1.scale\n",
      "remove key: opt_state.mu.params.decoder.layers.pre_self_attention_layer_norm_2.scale\n",
      "remove key: opt_state.mu.params.decoder.layers.pre_self_attention_layer_norm_3.scale\n",
      "remove key: opt_state.mu.params.decoder.layers.self_attention_0.AttentionOp_0.dyn_w_proj.dd.kernel\n",
      "remove key: opt_state.mu.params.decoder.layers.self_attention_0.AttentionOp_0.dyn_w_proj.dw1.kernel\n",
      "remove key: opt_state.mu.params.decoder.layers.self_attention_0.AttentionOp_0.dyn_w_proj.qkw\n",
      "remove key: opt_state.mu.params.decoder.layers.self_attention_0.out.kernel\n",
      "remove key: opt_state.mu.params.decoder.layers.self_attention_0.k_norm.scale\n",
      "remove key: opt_state.mu.params.decoder.layers.self_attention_0.key.kernel\n",
      "remove key: opt_state.mu.params.decoder.layers.self_attention_0.query.kernel\n",
      "remove key: opt_state.mu.params.decoder.layers.self_attention_0.q_norm.scale\n",
      "remove key: opt_state.mu.params.decoder.layers.self_attention_0.value.kernel\n",
      "remove key: opt_state.mu.params.decoder.layers.self_attention_1.AttentionOp_0.dyn_w_proj.dd.kernel\n",
      "remove key: opt_state.mu.params.decoder.layers.self_attention_1.AttentionOp_0.dyn_w_proj.dw1.kernel\n",
      "remove key: opt_state.mu.params.decoder.layers.self_attention_1.AttentionOp_0.dyn_w_proj.qkw\n",
      "remove key: opt_state.mu.params.decoder.layers.self_attention_1.out.kernel\n",
      "remove key: opt_state.mu.params.decoder.layers.self_attention_1.k_norm.scale\n",
      "remove key: opt_state.mu.params.decoder.layers.self_attention_1.key.kernel\n",
      "remove key: opt_state.mu.params.decoder.layers.self_attention_1.query.kernel\n",
      "remove key: opt_state.mu.params.decoder.layers.self_attention_1.q_norm.scale\n",
      "remove key: opt_state.mu.params.decoder.layers.self_attention_1.value.kernel\n",
      "remove key: opt_state.mu.params.decoder.layers.self_attention_2.AttentionOp_0.dyn_w_proj.dd.kernel\n",
      "remove key: opt_state.mu.params.decoder.layers.self_attention_2.AttentionOp_0.dyn_w_proj.dw1.kernel\n",
      "remove key: opt_state.mu.params.decoder.layers.self_attention_2.AttentionOp_0.dyn_w_proj.qkw\n",
      "remove key: opt_state.mu.params.decoder.layers.self_attention_2.out.kernel\n",
      "remove key: opt_state.mu.params.decoder.layers.self_attention_2.k_norm.scale\n",
      "remove key: opt_state.mu.params.decoder.layers.self_attention_2.key.kernel\n",
      "remove key: opt_state.mu.params.decoder.layers.self_attention_2.query.kernel\n",
      "remove key: opt_state.mu.params.decoder.layers.self_attention_2.q_norm.scale\n",
      "remove key: opt_state.mu.params.decoder.layers.self_attention_2.value.kernel\n",
      "remove key: opt_state.mu.params.decoder.layers.self_attention_3.AttentionOp_0.dyn_w_proj.dd.kernel\n",
      "remove key: opt_state.mu.params.decoder.layers.self_attention_3.AttentionOp_0.dyn_w_proj.dw1.kernel\n",
      "remove key: opt_state.mu.params.decoder.layers.self_attention_3.AttentionOp_0.dyn_w_proj.qkw\n",
      "remove key: opt_state.mu.params.decoder.layers.self_attention_3.out.kernel\n",
      "remove key: opt_state.mu.params.decoder.layers.self_attention_3.k_norm.scale\n",
      "remove key: opt_state.mu.params.decoder.layers.self_attention_3.key.kernel\n",
      "remove key: opt_state.mu.params.decoder.layers.self_attention_3.query.kernel\n",
      "remove key: opt_state.mu.params.decoder.layers.self_attention_3.q_norm.scale\n",
      "remove key: opt_state.mu.params.decoder.layers.self_attention_3.value.kernel\n",
      "remove key: opt_state.mu.params.decoder.logits_dense.kernel\n",
      "remove key: opt_state.nu.params.token_embedder.embedding\n",
      "remove key: opt_state.nu.params.decoder.decoder_norm.scale\n",
      "remove key: opt_state.nu.params.decoder.layers.unshared_mlp_0.wi_0\n",
      "remove key: opt_state.nu.params.decoder.layers.unshared_mlp_0.wi_1\n",
      "remove key: opt_state.nu.params.decoder.layers.unshared_mlp_0.wo\n",
      "remove key: opt_state.nu.params.decoder.layers.unshared_mlp_0.mgate\n",
      "remove key: opt_state.nu.params.decoder.layers.unshared_mlp_0.router_gate.kernel\n",
      "remove key: opt_state.nu.params.decoder.layers.unshared_mlp_2.wi_0\n",
      "remove key: opt_state.nu.params.decoder.layers.unshared_mlp_2.wi_1\n",
      "remove key: opt_state.nu.params.decoder.layers.unshared_mlp_2.wo\n",
      "remove key: opt_state.nu.params.decoder.layers.unshared_mlp_2.mgate\n",
      "remove key: opt_state.nu.params.decoder.layers.unshared_mlp_2.router_gate.kernel\n",
      "remove key: opt_state.nu.params.decoder.layers.mlp_0.wi_0.kernel\n",
      "remove key: opt_state.nu.params.decoder.layers.mlp_0.wi_1.kernel\n",
      "remove key: opt_state.nu.params.decoder.layers.mlp_0.wo.kernel\n",
      "remove key: opt_state.nu.params.decoder.layers.mlp_0.mgate.kernel\n",
      "remove key: opt_state.nu.params.decoder.layers.mlp_1.wi_0.kernel\n",
      "remove key: opt_state.nu.params.decoder.layers.mlp_1.wi_1.kernel\n",
      "remove key: opt_state.nu.params.decoder.layers.mlp_1.wo.kernel\n",
      "remove key: opt_state.nu.params.decoder.layers.mlp_1.mgate.kernel\n",
      "remove key: opt_state.nu.params.decoder.layers.mlp_2.wi_0.kernel\n",
      "remove key: opt_state.nu.params.decoder.layers.mlp_2.wi_1.kernel\n",
      "remove key: opt_state.nu.params.decoder.layers.mlp_2.wo.kernel\n",
      "remove key: opt_state.nu.params.decoder.layers.mlp_2.mgate.kernel\n",
      "remove key: opt_state.nu.params.decoder.layers.mlp_3.wi_0.kernel\n",
      "remove key: opt_state.nu.params.decoder.layers.mlp_3.wi_1.kernel\n",
      "remove key: opt_state.nu.params.decoder.layers.mlp_3.wo.kernel\n",
      "remove key: opt_state.nu.params.decoder.layers.mlp_3.mgate.kernel\n",
      "remove key: opt_state.nu.params.decoder.layers.post_self_attention_layer_norm_0.scale\n",
      "remove key: opt_state.nu.params.decoder.layers.post_self_attention_layer_norm_1.scale\n",
      "remove key: opt_state.nu.params.decoder.layers.post_self_attention_layer_norm_2.scale\n",
      "remove key: opt_state.nu.params.decoder.layers.post_self_attention_layer_norm_3.scale\n",
      "remove key: opt_state.nu.params.decoder.layers.pre_self_attention_layer_norm_0.scale\n",
      "remove key: opt_state.nu.params.decoder.layers.pre_self_attention_layer_norm_1.scale\n",
      "remove key: opt_state.nu.params.decoder.layers.pre_self_attention_layer_norm_2.scale\n",
      "remove key: opt_state.nu.params.decoder.layers.pre_self_attention_layer_norm_3.scale\n",
      "remove key: opt_state.nu.params.decoder.layers.self_attention_0.AttentionOp_0.dyn_w_proj.dd.kernel\n",
      "remove key: opt_state.nu.params.decoder.layers.self_attention_0.AttentionOp_0.dyn_w_proj.dw1.kernel\n",
      "remove key: opt_state.nu.params.decoder.layers.self_attention_0.AttentionOp_0.dyn_w_proj.qkw\n",
      "remove key: opt_state.nu.params.decoder.layers.self_attention_0.out.kernel\n",
      "remove key: opt_state.nu.params.decoder.layers.self_attention_0.k_norm.scale\n",
      "remove key: opt_state.nu.params.decoder.layers.self_attention_0.key.kernel\n",
      "remove key: opt_state.nu.params.decoder.layers.self_attention_0.query.kernel\n",
      "remove key: opt_state.nu.params.decoder.layers.self_attention_0.q_norm.scale\n",
      "remove key: opt_state.nu.params.decoder.layers.self_attention_0.value.kernel\n",
      "remove key: opt_state.nu.params.decoder.layers.self_attention_1.AttentionOp_0.dyn_w_proj.dd.kernel\n",
      "remove key: opt_state.nu.params.decoder.layers.self_attention_1.AttentionOp_0.dyn_w_proj.dw1.kernel\n",
      "remove key: opt_state.nu.params.decoder.layers.self_attention_1.AttentionOp_0.dyn_w_proj.qkw\n",
      "remove key: opt_state.nu.params.decoder.layers.self_attention_1.out.kernel\n",
      "remove key: opt_state.nu.params.decoder.layers.self_attention_1.k_norm.scale\n",
      "remove key: opt_state.nu.params.decoder.layers.self_attention_1.key.kernel\n",
      "remove key: opt_state.nu.params.decoder.layers.self_attention_1.query.kernel\n",
      "remove key: opt_state.nu.params.decoder.layers.self_attention_1.q_norm.scale\n",
      "remove key: opt_state.nu.params.decoder.layers.self_attention_1.value.kernel\n",
      "remove key: opt_state.nu.params.decoder.layers.self_attention_2.AttentionOp_0.dyn_w_proj.dd.kernel\n",
      "remove key: opt_state.nu.params.decoder.layers.self_attention_2.AttentionOp_0.dyn_w_proj.dw1.kernel\n",
      "remove key: opt_state.nu.params.decoder.layers.self_attention_2.AttentionOp_0.dyn_w_proj.qkw\n",
      "remove key: opt_state.nu.params.decoder.layers.self_attention_2.out.kernel\n",
      "remove key: opt_state.nu.params.decoder.layers.self_attention_2.k_norm.scale\n",
      "remove key: opt_state.nu.params.decoder.layers.self_attention_2.key.kernel\n",
      "remove key: opt_state.nu.params.decoder.layers.self_attention_2.query.kernel\n",
      "remove key: opt_state.nu.params.decoder.layers.self_attention_2.q_norm.scale\n",
      "remove key: opt_state.nu.params.decoder.layers.self_attention_2.value.kernel\n",
      "remove key: opt_state.nu.params.decoder.layers.self_attention_3.AttentionOp_0.dyn_w_proj.dd.kernel\n",
      "remove key: opt_state.nu.params.decoder.layers.self_attention_3.AttentionOp_0.dyn_w_proj.dw1.kernel\n",
      "remove key: opt_state.nu.params.decoder.layers.self_attention_3.AttentionOp_0.dyn_w_proj.qkw\n",
      "remove key: opt_state.nu.params.decoder.layers.self_attention_3.out.kernel\n",
      "remove key: opt_state.nu.params.decoder.layers.self_attention_3.k_norm.scale\n",
      "remove key: opt_state.nu.params.decoder.layers.self_attention_3.key.kernel\n",
      "remove key: opt_state.nu.params.decoder.layers.self_attention_3.query.kernel\n",
      "remove key: opt_state.nu.params.decoder.layers.self_attention_3.q_norm.scale\n",
      "remove key: opt_state.nu.params.decoder.layers.self_attention_3.value.kernel\n",
      "remove key: opt_state.nu.params.decoder.logits_dense.kernel\n",
      "remove key: opt_state.count\n",
      "encode_unshared_mlp_1: params.params.decoder.layers.unshared_mlp_1.wi_0\n",
      "encode_unshared_mlp_3: params.params.decoder.layers.unshared_mlp_3.wi_0\n",
      "encode_unshared_mlp_1: params.params.decoder.layers.unshared_mlp_1.wi_1\n",
      "encode_unshared_mlp_3: params.params.decoder.layers.unshared_mlp_3.wi_1\n",
      "encode_unshared_mlp_1: params.params.decoder.layers.unshared_mlp_1.wo\n",
      "encode_unshared_mlp_3: params.params.decoder.layers.unshared_mlp_3.wo\n",
      "encode_unshared_mlp_1: params.params.decoder.layers.unshared_mlp_1.mgate\n",
      "encode_unshared_mlp_3: params.params.decoder.layers.unshared_mlp_3.mgate\n",
      "encode_unshared_mlp_1: params.params.decoder.layers.unshared_mlp_1.router_gate.kernel\n",
      "encode_unshared_mlp_3: params.params.decoder.layers.unshared_mlp_3.router_gate.kernel\n",
      "remove key: params.params.decoder.layers.mlp_0.wi_0.kernel\n",
      "remove key: params.params.decoder.layers.mlp_0.wi_1.kernel\n",
      "remove key: params.params.decoder.layers.mlp_0.wo.kernel\n",
      "remove key: params.params.decoder.layers.mlp_0.mgate.kernel\n",
      "remove key: params.params.decoder.layers.mlp_1.wi_0.kernel\n",
      "remove key: params.params.decoder.layers.mlp_1.wi_1.kernel\n",
      "remove key: params.params.decoder.layers.mlp_1.wo.kernel\n",
      "remove key: params.params.decoder.layers.mlp_1.mgate.kernel\n",
      "remove key: params.params.decoder.layers.mlp_2.wi_0.kernel\n",
      "remove key: params.params.decoder.layers.mlp_2.wi_1.kernel\n",
      "remove key: params.params.decoder.layers.mlp_2.wo.kernel\n",
      "remove key: params.params.decoder.layers.mlp_2.mgate.kernel\n",
      "remove key: params.params.decoder.layers.mlp_3.wi_0.kernel\n",
      "remove key: params.params.decoder.layers.mlp_3.wi_1.kernel\n",
      "remove key: params.params.decoder.layers.mlp_3.wo.kernel\n",
      "remove key: params.params.decoder.layers.mlp_3.mgate.kernel\n"
     ]
    }
   ],
   "source": [
    "# 基于tpu type 构建_sharding文件\n",
    "import base64\n",
    "\n",
    "def decode_base64(encoded_str):\n",
    "    decoded_bytes = base64.b64decode(encoded_str)\n",
    "    decoded_str = decoded_bytes.decode('utf-8')\n",
    "    return decoded_str\n",
    "\n",
    "def encode_base64(decoded_str):\n",
    "    # decoded_str = \"opt_state.mu.params.token_embedder.embedding\"\n",
    "    encoded_string = base64.b64encode(decoded_str.encode('utf-8')).decode('utf-8')\n",
    "    return encoded_string\n",
    "\n",
    "'''\n",
    "_sharding文件格式如下：\n",
    "{\n",
    "  b3B0X3N0YXRlLm11LnBhcmFtcy50b2tlbl9lbWJlZGRlci5lbWJlZGRpbmc=': {'sharding_type': 'NamedSharding',\n",
    "  'shape': [1, 1, 4, 1, 1, 1, 1],\n",
    "  'axis_names': ['data', 'stage', 'fsdp', 'fsdp_transpose', 'sequence', 'tensor','autoregressive'],\n",
    "  'partition_spec': [['tensor', 'autoregressive'], ['fsdp', 'fsdp_transpose', 'sequence']],\n",
    "   2: 4},\n",
    "   ...\n",
    "   }\n",
    "   '''\n",
    "# moe sharding\n",
    "_sharding_path = 'gs://llm_base_models_us-east5/v5p_256/7B/xm_45x7B_moe_1017/xm3p5_moe_params_no_opt_v5p_64_sharding.copy'\n",
    "_sharding_path = epath.Path(_sharding_path)\n",
    "# 读取已有的_sharding文件\n",
    "with _sharding_path.open('r') as f:\n",
    "    _sharding = json.load(f)\n",
    "\n",
    "tpu_type = 'v5p-32'\n",
    "core_nums = int(tpu_type.split('-')[-1])\n",
    "if 'v3' not in tpu_type:\n",
    "    core_nums = core_nums // 2\n",
    "print(f'core_nums: {core_nums}')\n",
    "updated_sharding = {}\n",
    "for k, v in _sharding.items():\n",
    "    if isinstance(v, str):\n",
    "        v = json.loads(v)\n",
    "    v['shape'][2] = core_nums\n",
    "    if len(v['shape']) == 8:\n",
    "        v['shape'] = v['shape'][:-1]\n",
    "    base_k = decode_base64(k)\n",
    "    if 'opt_state' in base_k or 'layers.mlp' in base_k: \n",
    "        print(f'remove key: {base_k}')\n",
    "        continue\n",
    "    updated_sharding[k] = json.dumps(v)\n",
    "    if 'unshared_mlp_0' in base_k: # 因为已有的sharding文件是隔层moe，因此需要进行扩展\n",
    "        unshared_mlp_1 = base_k.replace('unshared_mlp_0', 'unshared_mlp_1')\n",
    "        unshared_mlp_3 = base_k.replace('unshared_mlp_0', 'unshared_mlp_3')\n",
    "        encode_unshared_mlp_1 = encode_base64(unshared_mlp_1)\n",
    "        encode_unshared_mlp_3 = encode_base64(unshared_mlp_3)\n",
    "        print(f'encode_unshared_mlp_1: {unshared_mlp_1}')\n",
    "        print(f'encode_unshared_mlp_3: {unshared_mlp_3}')\n",
    "        \n",
    "        updated_sharding[encode_unshared_mlp_1] = json.dumps(v)\n",
    "        updated_sharding[encode_unshared_mlp_3] = json.dumps(v)\n",
    "    \n",
    "updated_sharding_path = f'{save_dir}/{params_save_step}/state/_sharding'\n",
    "\n",
    "updated_sharding_path = epath.Path(updated_sharding_path)\n",
    "with updated_sharding_path.open('w') as f:\n",
    "    json.dump(updated_sharding, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
